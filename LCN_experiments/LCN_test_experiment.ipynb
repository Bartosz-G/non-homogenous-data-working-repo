{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAPhXEZ2SNKL","executionInfo":{"status":"ok","timestamp":1692979001816,"user_tz":-60,"elapsed":17804,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"8c08549f-39ae-48e2-df79-9b5266c81e72"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping TabularExperimentTrackerClient as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mCollecting git+https://github.com/DanielWarfield1/TabularExperimentTrackerClient\n","  Cloning https://github.com/DanielWarfield1/TabularExperimentTrackerClient to /tmp/pip-req-build-2b19l0ou\n","  Running command git clone --filter=blob:none --quiet https://github.com/DanielWarfield1/TabularExperimentTrackerClient /tmp/pip-req-build-2b19l0ou\n","  Resolved https://github.com/DanielWarfield1/TabularExperimentTrackerClient to commit df52eac0ce37df983d93a1b76cb9f4380a27b40d\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting openml (from TabularExperimentTrackerClient==0.0.1)\n","  Downloading openml-0.14.1.tar.gz (131 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from TabularExperimentTrackerClient==0.0.1) (2.31.0)\n","Collecting liac-arff>=2.4.0 (from openml->TabularExperimentTrackerClient==0.0.1)\n","  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting xmltodict (from openml->TabularExperimentTrackerClient==0.0.1)\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from openml->TabularExperimentTrackerClient==0.0.1) (1.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from openml->TabularExperimentTrackerClient==0.0.1) (2.8.2)\n","Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from openml->TabularExperimentTrackerClient==0.0.1) (1.5.3)\n","Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from openml->TabularExperimentTrackerClient==0.0.1) (1.10.1)\n","Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from openml->TabularExperimentTrackerClient==0.0.1) (1.23.5)\n","Collecting minio (from openml->TabularExperimentTrackerClient==0.0.1)\n","  Downloading minio-7.1.16-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from openml->TabularExperimentTrackerClient==0.0.1) (9.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->TabularExperimentTrackerClient==0.0.1) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->TabularExperimentTrackerClient==0.0.1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->TabularExperimentTrackerClient==0.0.1) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->TabularExperimentTrackerClient==0.0.1) (2023.7.22)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->openml->TabularExperimentTrackerClient==0.0.1) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->openml->TabularExperimentTrackerClient==0.0.1) (1.16.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml->TabularExperimentTrackerClient==0.0.1) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml->TabularExperimentTrackerClient==0.0.1) (3.2.0)\n","Building wheels for collected packages: TabularExperimentTrackerClient, openml, liac-arff\n","  Building wheel for TabularExperimentTrackerClient (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for TabularExperimentTrackerClient: filename=TabularExperimentTrackerClient-0.0.1-py3-none-any.whl size=6378 sha256=da5d1485f629b22ef561e0e63e84ab70e7e9db36eaa1548f07d058088469ac63\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-z_mya3p5/wheels/f9/2e/f3/69345202c956e07475c8f2f55074ad4d97b3e6a976b70fafab\n","  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openml: filename=openml-0.14.1-py3-none-any.whl size=146924 sha256=407fc438dfa00b362c71957f3ae74894551316089640644ffab97c0eaeb953ae\n","  Stored in directory: /root/.cache/pip/wheels/75/bc/fd/739778254a2881ef96b139d0aaf60c6d4f9130bb1459b48f10\n","  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11717 sha256=d6db0a7a6135d4c3dd741f14f6f66facf4dc13f92db3de52d498d0638d9a07d1\n","  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n","Successfully built TabularExperimentTrackerClient openml liac-arff\n","Installing collected packages: xmltodict, minio, liac-arff, openml, TabularExperimentTrackerClient\n","Successfully installed TabularExperimentTrackerClient-0.0.1 liac-arff-2.5.0 minio-7.1.16 openml-0.14.1 xmltodict-0.13.0\n"]}],"source":["!pip uninstall TabularExperimentTrackerClient --y\n","!pip install git+https://github.com/DanielWarfield1/TabularExperimentTrackerClient"]},{"cell_type":"code","source":["!pip install numpy\n","!pip install pandas\n","!pip install scikit-learn\n","!pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mLuLJlf9StGX","executionInfo":{"status":"ok","timestamp":1692979033774,"user_tz":-60,"elapsed":31966,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"857eea18-96f5-4525-d93f-922be11b9bbf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip uninstall NeuralNetworksTrainingPackage --y\n","!pip install git+https://github.com/Bartosz-G/NeuralNetworksTrainingPackage"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USjjPIj6rB88","executionInfo":{"status":"ok","timestamp":1692979044029,"user_tz":-60,"elapsed":10264,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"a7a299a7-255c-4a62-913a-bd071039f0f3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping NeuralNetworksTrainingPackage as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mCollecting git+https://github.com/Bartosz-G/NeuralNetworksTrainingPackage\n","  Cloning https://github.com/Bartosz-G/NeuralNetworksTrainingPackage to /tmp/pip-req-build-e1b99czb\n","  Running command git clone --filter=blob:none --quiet https://github.com/Bartosz-G/NeuralNetworksTrainingPackage /tmp/pip-req-build-e1b99czb\n","  Resolved https://github.com/Bartosz-G/NeuralNetworksTrainingPackage to commit 828b853d316fc48e520073c3e092089e4d0a9d95\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from NeuralNetworksTrainingPackage==1.0.0) (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from NeuralNetworksTrainingPackage==1.0.0) (1.5.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from NeuralNetworksTrainingPackage==1.0.0) (1.2.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from NeuralNetworksTrainingPackage==1.0.0) (2.0.1+cu118)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->NeuralNetworksTrainingPackage==1.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->NeuralNetworksTrainingPackage==1.0.0) (2023.3)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->NeuralNetworksTrainingPackage==1.0.0) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->NeuralNetworksTrainingPackage==1.0.0) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->NeuralNetworksTrainingPackage==1.0.0) (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->NeuralNetworksTrainingPackage==1.0.0) (3.27.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->NeuralNetworksTrainingPackage==1.0.0) (16.0.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->NeuralNetworksTrainingPackage==1.0.0) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->NeuralNetworksTrainingPackage==1.0.0) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->NeuralNetworksTrainingPackage==1.0.0) (1.3.0)\n","Building wheels for collected packages: NeuralNetworksTrainingPackage\n","  Building wheel for NeuralNetworksTrainingPackage (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NeuralNetworksTrainingPackage: filename=NeuralNetworksTrainingPackage-1.0.0-py3-none-any.whl size=4480 sha256=f86e0dcedba5c55bb957f663d8242f1dd3a6dd711dbeeb1932aef19c466aae56\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-p8mpd34y/wheels/82/01/e8/da81de869be2f6b8c193a6fc5c42ee3ff0b6b97a7b70cd565a\n","Successfully built NeuralNetworksTrainingPackage\n","Installing collected packages: NeuralNetworksTrainingPackage\n","Successfully installed NeuralNetworksTrainingPackage-1.0.0\n"]}]},{"cell_type":"code","source":["from NNTraining import *\n","# Global namespace:\n","# Hyperparams(**run_info.get('hyp'))\n","# CustomDataset(X, Y, relative_indices, tensor_type=torch.float)\n","# CustomDatasetWrapper(train_dataset, relative_indices)\n","# kfold_dataloader_iterator(dataset, n_splits=10, random_state=42, batch_size=16, shuffle_kfold=True, shuffle_dataloader=True)\n","# get_train_test(X, y, categorical_indicator, attribute_names, train_split, seed)"],"metadata":{"id":"2i6wKLMbSm5M","executionInfo":{"status":"ok","timestamp":1692979050690,"user_tz":-60,"elapsed":6671,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import sklearn\n","import torch"],"metadata":{"id":"HBbb4I8IzD2Z","executionInfo":{"status":"ok","timestamp":1692979050691,"user_tz":-60,"elapsed":7,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from TabularExperimentTrackerClient.ExperimentClient import ExperimentClient\n","\n","# ==== Setup ====\n","#creating experiment client utilities\n","ex = ExperimentClient(verbose = True)\n","if True:\n","\n","    # BART\n","\n","    #getting openml credentials from drive\n","    ex.define_opml_cred_drive('/My Drive/research/non-homogenous-data/creds/creds-openml.txt')\n","    #getting orchestration credentials from drive\n","    ex.define_orch_cred_drive('bart', '/My Drive//research/non-homogenous-data/creds/creds-colab.txt')\n","\n","else:\n","\n","    # DANIEL\n","\n","    #getting openml credentials from drive\n","    ex.define_opml_cred_drive('/My Drive/Colab Notebooks/Non-Homogeneous Data/openMLAPIKey.txt')\n","    #getting orchestration credentials from drive\n","    ex.define_orch_cred_drive('test1', '/My Drive/Colab Notebooks/Non-Homogeneous Data/tabExpTrackAPIKey.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hloNgGeKSypk","executionInfo":{"status":"ok","timestamp":1692979078060,"user_tz":-60,"elapsed":27374,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"15a78627-d4d6-40ab-fabb-6dae38af6421"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Parameters varying\n","depth = {'distribution': 'int_uniform', 'min':1, 'max':11}\n","seed = {'distribution': 'constant', 'value': 42}\n","drop_type = {'distribution': 'categorical', 'values':['node_dropconnect', 'none']}\n","p = {'distribution': 'int_uniform', 'min':0, 'max':1}\n","back_n = {'distribution': 'categorical', 'values':[0, 0, 0, 1]}\n","hidden_dim = {'distribution': 'constant', 'value': 1} # Assertion error coming from Net if not 1\n","anneal = {'distribution': 'categorical', 'values':['interpolation', 'none', 'approx']}\n","batch_size = {'distribution': 'categorical', 'values':[16,32,64,64,64,128,256]}\n","epochs = {'distribution': 'categorical', 'values':[30, 60, 90]}\n","lr = {'distribution': 'log_uniform', 'min':0.05, 'max':0.2} # yields mean = 0.1082, median 0.1\n","momentum = {'distribution': 'constant', 'value': 0.9}\n","no_cuda = {'distribution': 'constant', 'value': False}\n","lr_step_size = {'distribution': 'categorical', 'values':[10, 10, 15, 20]}\n","gamma = {'distribution': 'constant', 'value': 0.1}\n","\n","\n","\n","\n","# Regression Spaces\n","LCN_reg_SGD_space = {\n","    'depth': depth,\n","    'seed': seed,\n","    'drop_type': drop_type,\n","    'p': p,\n","    'ensemble_n': {'distribution': 'constant', 'value': 1},\n","    'shrinkage': {'distribution': 'constant', 'value': 1},\n","    'back_n': back_n,\n","    'net_type': {'distribution': 'constant', 'value': 'locally_constant'},\n","    'hidden_dim': hidden_dim,\n","    'anneal': anneal,\n","    'optimizer': {'distribution': 'constant', 'value': 'SGD'},\n","    'batch_size': batch_size,\n","    'epochs': epochs,\n","    'lr': lr,\n","    'momentum': momentum,\n","    'no_cuda': no_cuda,\n","    'lr_step_size': lr_step_size,\n","    'gamma': gamma,\n","    'task': {'distribution': 'constant', 'value': 'regression'}\n","    }\n","\n","LCN_reg_AMSGrad_space = {\n","    'depth': depth,\n","    'seed': seed,\n","    'drop_type': drop_type,\n","    'p': p,\n","    'ensemble_n': {'distribution': 'constant', 'value': 1},\n","    'shrinkage': {'distribution': 'constant', 'value': 1},\n","    'back_n': back_n,\n","    'net_type': {'distribution': 'constant', 'value': 'locally_constant'},\n","    'hidden_dim': hidden_dim,\n","    'anneal': anneal,\n","    'optimizer': {'distribution': 'constant', 'value': 'AMSGrad'},\n","    'batch_size': batch_size,\n","    'epochs': epochs,\n","    'lr': lr,\n","    'momentum': momentum,\n","    'no_cuda': no_cuda,\n","    'lr_step_size': lr_step_size,\n","    'gamma': gamma,\n","    'task': {'distribution': 'constant', 'value': 'regression'}\n","    }\n","\n","LLN_reg_SGD_space = {\n","    'depth': depth,\n","    'seed': seed,\n","    'drop_type': drop_type,\n","    'p': p,\n","    'ensemble_n': {'distribution': 'constant', 'value': 1},\n","    'shrinkage': {'distribution': 'constant', 'value': 1},\n","    'back_n': back_n,\n","    'net_type': {'distribution': 'constant', 'value': 'locally_linear'},\n","    'hidden_dim': hidden_dim,\n","    'anneal': anneal,\n","    'optimizer': {'distribution': 'constant', 'value': 'SGD'},\n","    'batch_size': batch_size,\n","    'epochs': epochs,\n","    'lr': lr,\n","    'momentum': momentum,\n","    'no_cuda': no_cuda,\n","    'lr_step_size': lr_step_size,\n","    'gamma': gamma,\n","    'task': {'distribution': 'constant', 'value': 'regression'}\n","    }\n","\n","\n","LLN_reg_AMSGrad_space = {\n","    'depth': depth,\n","    'seed': seed,\n","    'drop_type': drop_type,\n","    'p': p,\n","    'ensemble_n': {'distribution': 'constant', 'value': 1},\n","    'shrinkage': {'distribution': 'constant', 'value': 1},\n","    'back_n': back_n,\n","    'net_type': {'distribution': 'constant', 'value': 'locally_linear'},\n","    'hidden_dim': hidden_dim,\n","    'anneal': anneal,\n","    'optimizer': {'distribution': 'constant', 'value': 'AMSGrad'},\n","    'batch_size': batch_size,\n","    'epochs': epochs,\n","    'lr': lr,\n","    'momentum': momentum,\n","    'no_cuda': no_cuda,\n","    'lr_step_size': lr_step_size,\n","    'gamma': gamma,\n","    'task': {'distribution': 'constant', 'value': 'regression'}\n","    }\n","\n","# Classification spaces\n","\n","LCN_cls_SGD_space = {\n","    'depth': depth,\n","    'seed': seed,\n","    'drop_type': drop_type,\n","    'p': p,\n","    'ensemble_n': {'distribution': 'constant', 'value': 1},\n","    'shrinkage': {'distribution': 'constant', 'value': 1},\n","    'back_n': back_n,\n","    'net_type': {'distribution': 'constant', 'value': 'locally_constant'},\n","    'hidden_dim': hidden_dim,\n","    'anneal': anneal,\n","    'optimizer': {'distribution': 'constant', 'value': 'SGD'},\n","    'batch_size': batch_size,\n","    'epochs': epochs,\n","    'lr': lr,\n","    'momentum': momentum,\n","    'no_cuda': no_cuda,\n","    'lr_step_size': lr_step_size,\n","    'gamma': gamma,\n","    'task': {'distribution': 'constant', 'value': 'classification'}\n","    }\n","\n","LCN_cls_AMSGrad_space = {\n","    'depth': depth,\n","    'seed': seed,\n","    'drop_type': drop_type,\n","    'p': p,\n","    'ensemble_n': {'distribution': 'constant', 'value': 1},\n","    'shrinkage': {'distribution': 'constant', 'value': 1},\n","    'back_n': back_n,\n","    'net_type': {'distribution': 'constant', 'value': 'locally_constant'},\n","    'hidden_dim': hidden_dim,\n","    'anneal': anneal,\n","    'optimizer': {'distribution': 'constant', 'value': 'AMSGrad'},\n","    'batch_size': batch_size,\n","    'epochs': epochs,\n","    'lr': lr,\n","    'momentum': momentum,\n","    'no_cuda': no_cuda,\n","    'lr_step_size': lr_step_size,\n","    'gamma': gamma,\n","    'task': {'distribution': 'constant', 'value': 'classification'}\n","    }\n","\n","LLN_cls_SGD_space = {\n","    'depth': depth,\n","    'seed': seed,\n","    'drop_type': drop_type,\n","    'p': p,\n","    'ensemble_n': {'distribution': 'constant', 'value': 1},\n","    'shrinkage': {'distribution': 'constant', 'value': 1},\n","    'back_n': back_n,\n","    'net_type': {'distribution': 'constant', 'value': 'locally_linear'},\n","    'hidden_dim': hidden_dim,\n","    'anneal': anneal,\n","    'optimizer': {'distribution': 'constant', 'value': 'SGD'},\n","    'batch_size': batch_size,\n","    'epochs': epochs,\n","    'lr': lr,\n","    'momentum': momentum,\n","    'no_cuda': no_cuda,\n","    'lr_step_size': lr_step_size,\n","    'gamma': gamma,\n","    'task': {'distribution': 'constant', 'value': 'classification'}\n","    }\n","\n","\n","LLN_cls_AMSGrad_space = {\n","    'depth': depth,\n","    'seed': seed,\n","    'drop_type': drop_type,\n","    'p': p,\n","    'ensemble_n': {'distribution': 'constant', 'value': 1},\n","    'shrinkage': {'distribution': 'constant', 'value': 1},\n","    'back_n': back_n,\n","    'net_type': {'distribution': 'constant', 'value': 'locally_linear'},\n","    'hidden_dim': hidden_dim,\n","    'anneal': anneal,\n","    'optimizer': {'distribution': 'constant', 'value': 'AMSGrad'},\n","    'batch_size': batch_size,\n","    'epochs': epochs,\n","    'lr': lr,\n","    'momentum': momentum,\n","    'no_cuda': no_cuda,\n","    'lr_step_size': lr_step_size,\n","    'gamma': gamma,\n","    'task': {'distribution': 'constant', 'value': 'classification'}\n","    }\n"],"metadata":{"id":"Nwt_9-JMTTft","executionInfo":{"status":"ok","timestamp":1692979078061,"user_tz":-60,"elapsed":7,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Testing Hyperparameter Spaces"],"metadata":{"id":"MP1WbmGEjSKT"}},{"cell_type":"code","source":["ex.monte_carlo_sample_space({\n","    # 'depth': depth,\n","    # 'seed': seed,\n","    'drop_type': drop_type,\n","    # 'p': p,\n","    # 'ensemble_n': {'distribution': 'constant', 'value': 1},\n","    # 'shrinkage': {'distribution': 'constant', 'value': 1},\n","    # 'back_n': back_n,\n","    # 'net_type': {'distribution': 'constant', 'value': 'locally_linear'},\n","    # 'hidden_dim': hidden_dim,\n","    # 'anneal': anneal,\n","    # 'optimizer': {'distribution': 'constant', 'value': 'AMSGrad'},\n","    # 'batch_size': batch_size,\n","    # 'epochs': epochs,\n","    # 'lr': lr,\n","    # 'momentum': momentum,\n","    # 'no_cuda': no_cuda,\n","    # 'lr_step_size': lr_step_size,\n","    # 'gamma': gamma,\n","    # 'task': {'distribution': 'constant', 'value': 'classification'}\n","    }, 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3BMwdFWjQi8","executionInfo":{"status":"ok","timestamp":1692979078762,"user_tz":-60,"elapsed":705,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"333659e4-c408-48fc-9682-e7c55a8f08b4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["sampled 1 points in the space:\n","{'drop_type': {'distribution': 'categorical', 'values': ['node_dropconnect', 'none']}}\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'drop_type': 'none'}]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["model_groups = {\n","    'LCN_reg_SGD':{'model':'LCN_reg_SGD', 'hype':LCN_reg_SGD_space},\n","    'LCN_reg_AMSGrad':{'model':'LCN_reg_AMSGrad', 'hype':LCN_reg_AMSGrad_space},\n","    'LLN_reg_SGD':{'model':'LLN_reg_SGD', 'hype':LLN_reg_SGD_space},\n","    'LLN_reg_AMSGrad':{'model':'LLN_reg_AMSGrad', 'hype':LLN_reg_AMSGrad_space},\n","    'LCN_cls_SGD':{'model':'LCN_cls_SGD', 'hype':LCN_cls_SGD_space},\n","    'LCN_cls_AMSGrad':{'model':'LCN_cls_AMSGrad', 'hype':LCN_cls_AMSGrad_space},\n","    'LLN_cls_SGD':{'model':'LLN_cls_SGD', 'hype':LLN_cls_SGD_space},\n","    'LLN_cls_AMSGrad':{'model':'LLN_cls_AMSGrad', 'hype':LLN_cls_AMSGrad_space},\n","}\n","\n","ex.def_model_groups(model_groups)"],"metadata":{"id":"cyzQSiOtzLBa","executionInfo":{"status":"ok","timestamp":1692979078763,"user_tz":-60,"elapsed":8,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["ex.def_data_groups_opml()\n","print('automatically defined data groups:')\n","print(ex.data_groups.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_hWhsfs9Lem","executionInfo":{"status":"ok","timestamp":1692979078763,"user_tz":-60,"elapsed":7,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"4484638c-19ea-4477-af5f-a6beb18535ac"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["automatically defined data groups:\n","dict_keys(['opml_reg_purnum_group', 'opml_class_purnum_group', 'opml_reg_numcat_group', 'opml_class_numcat_group'])\n"]}]},{"cell_type":"code","source":["classification_models = [k for k in model_groups.keys() if '_cls' in k]\n","regression_models = [k for k in model_groups.keys() if '_reg' in k]\n","\n","\n","applications = {'opml_reg_purnum_group': regression_models,\n","                'opml_reg_numcat_group': regression_models,\n","                'opml_class_purnum_group': classification_models,\n","                'opml_class_numcat_group': classification_models}\n","\n","ex.def_applications(applications)\n","ex.reg_experiment('Testing_LCN_4')\n","# ex.reg_experiment('20230822')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"9_3lujFq9gxJ","executionInfo":{"status":"ok","timestamp":1692979080094,"user_tz":-60,"elapsed":1334,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"60ff3345-3833-491e-edb1-29a2570c3816"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["existing experiment found\n"]},{"output_type":"execute_result","data":{"text/plain":["'existing experiment found'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["run_info = ex.begin_run_sticky()\n","run_info"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-j28taEW_XxU","executionInfo":{"status":"ok","timestamp":1692979081628,"user_tz":-60,"elapsed":1538,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"3603313c-930c-45cc-ff6a-fc7dd7963c54"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["{'_id': '64e8cf8829625b726f668ab4', 'metrics_per_epoch': [], 'experiment_id': '64e8b63efce6fc1c40c38231', 'experiment_name': 'Testing_LCN_4', 'mtpair_index': 157, 'mtpair_model': 'LCN_cls_AMSGrad', 'mtpair_task': '337-361062', 'is_completed': False, 'user_id': '64d3a7457658d6ec6db139d0', 'user_name': 'bart', 'hyp': {'depth': 5, 'seed': 42, 'drop_type': 'none', 'p': 1, 'ensemble_n': 1, 'shrinkage': 1, 'back_n': 1, 'net_type': 'locally_constant', 'hidden_dim': 1, 'anneal': 'interpolation', 'optimizer': 'AMSGrad', 'batch_size': 64, 'epochs': 90, 'lr': 0.05160704377702053, 'momentum': 0.9, 'no_cuda': False, 'lr_step_size': 10, 'gamma': 0.1, 'task': 'classification'}, 'model': 'LCN_cls_AMSGrad', 'task': '337-361062'}\n","4e8cf8829625b726f668ab\n"]},{"output_type":"execute_result","data":{"text/plain":["{'_id': '64e8cf8829625b726f668ab4',\n"," 'metrics_per_epoch': [],\n"," 'experiment_id': '64e8b63efce6fc1c40c38231',\n"," 'experiment_name': 'Testing_LCN_4',\n"," 'mtpair_index': 157,\n"," 'mtpair_model': 'LCN_cls_AMSGrad',\n"," 'mtpair_task': '337-361062',\n"," 'is_completed': False,\n"," 'user_id': '64d3a7457658d6ec6db139d0',\n"," 'user_name': 'bart',\n"," 'hyp': {'depth': 5,\n","  'seed': 42,\n","  'drop_type': 'none',\n","  'p': 1,\n","  'ensemble_n': 1,\n","  'shrinkage': 1,\n","  'back_n': 1,\n","  'net_type': 'locally_constant',\n","  'hidden_dim': 1,\n","  'anneal': 'interpolation',\n","  'optimizer': 'AMSGrad',\n","  'batch_size': 64,\n","  'epochs': 90,\n","  'lr': 0.05160704377702053,\n","  'momentum': 0.9,\n","  'no_cuda': False,\n","  'lr_step_size': 10,\n","  'gamma': 0.1,\n","  'task': 'classification'},\n"," 'model': 'LCN_cls_AMSGrad',\n"," 'task': '337-361062'}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["run_info.get('hyp')"],"metadata":{"id":"eHPE_iIMAr2_","executionInfo":{"status":"ok","timestamp":1692979081629,"user_tz":-60,"elapsed":14,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"581b3301-0605-4459-f73e-f57c74bbd1ab"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'depth': 5,\n"," 'seed': 42,\n"," 'drop_type': 'none',\n"," 'p': 1,\n"," 'ensemble_n': 1,\n"," 'shrinkage': 1,\n"," 'back_n': 1,\n"," 'net_type': 'locally_constant',\n"," 'hidden_dim': 1,\n"," 'anneal': 'interpolation',\n"," 'optimizer': 'AMSGrad',\n"," 'batch_size': 64,\n"," 'epochs': 90,\n"," 'lr': 0.05160704377702053,\n"," 'momentum': 0.9,\n"," 'no_cuda': False,\n"," 'lr_step_size': 10,\n"," 'gamma': 0.1,\n"," 'task': 'classification'}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["ex.opml_load_task(run_info['mtpair_task'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_jEa1jmiXaS6","executionInfo":{"status":"ok","timestamp":1692979093472,"user_tz":-60,"elapsed":11852,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"cce2af56-39c4-4994-f2b7-8d95d76aaf94"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading task 337-361062\n","task different than previous task, downloading...\n"]},{"output_type":"execute_result","data":{"text/plain":["(        f5   f6   f7  f8  f9  f13  f14  f15  f16  f17  ...  f24  f25  f26  \\\n"," 0      158  107   76  71  94    0    0   37   25    9  ...    0    0    0   \n"," 1      184   96   76  71  94    0   55   24   19   43  ...    0    0    0   \n"," 2       94  129   78  73  94    0   39   25    0    0  ...    0    0    0   \n"," 3       32  141   76  71  94    0    0    0    6    3  ...    0    0    0   \n"," 4       87   99  120  71  94    0   55   24    0    0  ...   24    0    0   \n"," ...    ...  ...  ...  ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n"," 10077   72   87   78  78  94    0    0   17    4   11  ...    0    0    0   \n"," 10078   59   86   76  71  94    0    0    3    1   15  ...    0    0    0   \n"," 10079   82   85   76  71  94    0    0    0   50   12  ...    0    0    0   \n"," 10080   87   98   76  71  94    0   54    2    0    0  ...    0    0    0   \n"," 10081   84   77   76  94  97    7    2   38   29    0  ...    0    0    0   \n"," \n","        f27  f28  f29  f30  f31  f32  f33  \n"," 0        0    0    0    0    0    0    0  \n"," 1        0    0    0    0    0    0    0  \n"," 2        2    0    0    0    0    0    0  \n"," 3        0    0    0    0    0    0    0  \n"," 4        0    0    0    0    0    0    0  \n"," ...    ...  ...  ...  ...  ...  ...  ...  \n"," 10077    0    5    1    0    0    0    0  \n"," 10078    0    0    0    0    0    0    0  \n"," 10079    0    0    0    0    0    0    0  \n"," 10080    0    0    0    0    0    0    0  \n"," 10081    0    0   10    8    0    0    0  \n"," \n"," [10082 rows x 26 columns],\n"," 0        N\n"," 1        N\n"," 2        N\n"," 3        N\n"," 4        N\n","         ..\n"," 10077    P\n"," 10078    P\n"," 10079    P\n"," 10080    P\n"," 10081    P\n"," Name: binaryClass, Length: 10082, dtype: category\n"," Categories (2, object): ['N' < 'P'],\n"," [False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False,\n","  False],\n"," ['f5',\n","  'f6',\n","  'f7',\n","  'f8',\n","  'f9',\n","  'f13',\n","  'f14',\n","  'f15',\n","  'f16',\n","  'f17',\n","  'f18',\n","  'f19',\n","  'f20',\n","  'f21',\n","  'f22',\n","  'f23',\n","  'f24',\n","  'f25',\n","  'f26',\n","  'f27',\n","  'f28',\n","  'f29',\n","  'f30',\n","  'f31',\n","  'f32',\n","  'f33'])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from NNTraining import *\n","args = Hyperparams(**run_info.get('hyp'))"],"metadata":{"id":"t7QejAbP-tGO","executionInfo":{"status":"ok","timestamp":1692979093472,"user_tz":-60,"elapsed":14,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# 1. LCN Model"],"metadata":{"id":"c6fWISMKznlN"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","\n","def my_softplus(x, tau=1., threshold=20.):\n","    truncate_mask = (x > threshold).type(torch.cuda.FloatTensor)\n","    return truncate_mask * x + (1. - truncate_mask) * (tau * torch.log(1 + torch.exp((1. - truncate_mask) * x / tau)))\n","\n","def my_softplus_derivative(x, tau=1., threshold=20.):\n","    truncate_mask = (x > threshold).type(torch.cuda.FloatTensor)\n","    return truncate_mask + (1. - truncate_mask) / (1 + torch.exp(- (1. - truncate_mask) * x / tau) )\n","\n","class Net(nn.Module):\n","    def __init__(self,\n","            input_dim,\n","            output_dim,\n","            hidden_dim,\n","            num_layer,\n","            num_back_layer,\n","            dense = False,\n","            drop_type = 'none',\n","            net_type = 'locally_constant',\n","            approx = 'none'):\n","        super(Net, self).__init__()\n","\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_layer = num_layer\n","        self.num_back_layer = num_back_layer\n","        self.dense = dense\n","        self.drop_type = drop_type\n","        self.net_type = net_type\n","        self.n_neuron = self.hidden_dim * self.num_layer\n","        self.approx = approx\n","\n","        self.layer = nn.ModuleList()\n","\n","        self.weights = dict()\n","        self.biases = dict()\n","        self.output_constants = dict()\n","        self.output_weights = dict()\n","        self.output_biases = dict()\n","\n","        accu_dim = input_dim\n","        self.weight_masks = []\n","        for i in range(self.num_layer):\n","            self.layer.append(nn.Linear(accu_dim, hidden_dim))\n","            ite_mask = np.zeros((1, hidden_dim, accu_dim))\n","            pick = np.random.choice(accu_dim, int(np.sqrt(accu_dim)), replace=False)\n","            ite_mask[0, 0, pick] = 1\n","            assert(hidden_dim == 1)\n","            ite_mask = torch.tensor(ite_mask.astype(np.float32)).cuda()\n","            self.weight_masks.append(ite_mask)\n","\n","            if self.dense:\n","                accu_dim += hidden_dim\n","            else:\n","                accu_dim = hidden_dim\n","\n","        if self.net_type == 'locally_constant':\n","            self.backward_layer = nn.ModuleList()\n","            backward_dim = 256\n","            cur_dim = self.num_layer * self.hidden_dim * (1 + self.input_dim)\n","            for i in range(self.num_back_layer):\n","                self.backward_layer.append(nn.Linear(cur_dim, backward_dim))\n","                cur_dim = backward_dim\n","            self.backward_layer.append(nn.Linear(cur_dim, output_dim))\n","\n","        elif self.net_type == 'locally_linear':\n","            self.output_fc = nn.Linear(accu_dim, self.output_dim)\n","        else:\n","            print('net_type', self.net_type, 'is not supported')\n","            exit(0)\n","\n","    def normal_forward(self, init_layer, p=0, training=True):\n","        assert(self.net_type == 'locally_linear')\n","        relu_masks = []\n","        if len(init_layer.shape) == 4:\n","            bz = init_layer.shape[0]\n","            init_layer = init_layer.view(bz, -1)\n","        cur_embed = init_layer\n","        batch_size = init_layer.shape[0]\n","\n","        for i in range(self.num_layer):\n","            if training == False:\n","                next_embed = self.layer[i](cur_embed)\n","            else:\n","                w = self.layer[i].weight\n","                w = w.view(1, w.shape[0], w.shape[1]).expand(batch_size, -1, -1)\n","\n","                b = self.layer[i].bias\n","                b = b.view(1, b.shape[0]).expand(batch_size, -1)\n","\n","                next_embed = torch.bmm(F.dropout(w, p=p, training=training), cur_embed.unsqueeze(-1)) + b.unsqueeze(-1)\n","                next_embed = next_embed.squeeze(-1)\n","\n","            relu_masks.append( (next_embed > 0) )\n","            next_embed = F.relu(next_embed)\n","            if self.dense:\n","                cur_embed = torch.cat((cur_embed, next_embed), 1)\n","            else:\n","                cur_embed = next_embed\n","        return self.output_fc(cur_embed), relu_masks\n","\n","    def forward(self, init_layer, p=0, training=True, alpha=None, anneal='none'):\n","        assert(self.net_type == 'locally_constant')\n","        relu_masks = []\n","        if len(init_layer.shape) == 4:\n","            bz = init_layer.shape[0]\n","            init_layer = init_layer.view(bz, -1)\n","        # cur_embed is used for forward computation.\n","        cur_embed = init_layer\n","        # x is used to compute Jacobian using dynamic programming.\n","        x = init_layer.unsqueeze(-1)\n","\n","        batch_size = x.shape[0]\n","        patterns = []\n","        for i in range(self.num_layer):\n","            if self.drop_type != 'node_dropconnect':\n","                next_embed = self.layer[i](cur_embed)\n","            w = self.layer[i].weight\n","            w = w.view(1, w.shape[0], w.shape[1]).expand(batch_size, -1, -1)\n","\n","            if self.drop_type == 'node_dropconnect':\n","                b = self.layer[i].bias\n","                b = b.view(1, b.shape[0]).expand(batch_size, -1)\n","\n","                next_embed = torch.bmm(F.dropout(w, p=p, training=training), cur_embed.unsqueeze(-1)) + b.unsqueeze(-1)\n","                next_embed = next_embed.squeeze(-1)\n","            else:\n","                pass\n","\n","            relu_masks.append( (next_embed > 0) )\n","            if self.approx == 'approx':\n","                neur_deriv = my_softplus_derivative(next_embed)\n","                next_embed = my_softplus(next_embed)\n","            elif anneal == 'interpolation':\n","                neur_deriv = alpha * (next_embed > 0).type(torch.cuda.FloatTensor) + (1 - alpha) * my_softplus_derivative(next_embed)\n","                next_embed = alpha * F.relu(next_embed) + (1 - alpha) * my_softplus(next_embed)\n","            elif anneal == 'none':\n","                neur_deriv = (next_embed > 0).type(torch.cuda.FloatTensor)\n","                next_embed = F.relu(next_embed)\n","\n","            patterns.append(neur_deriv)\n","            neur_deriv = neur_deriv.unsqueeze(-1)\n","\n","            if i == 0:\n","                jacobians = neur_deriv * w\n","                offsets = next_embed - torch.bmm(jacobians, x).squeeze(-1)\n","            else:\n","                if self.dense:\n","                    ite_jacobians = w[:, :, :self.input_dim] + torch.bmm(w[:, :, self.input_dim:], jacobians)\n","                else:\n","                    ite_jacobians = torch.bmm(w, jacobians[:, -self.hidden_dim:, :])\n","\n","                ite_jacobians = neur_deriv * ite_jacobians\n","                ite_offsets = next_embed - torch.bmm(ite_jacobians, x).squeeze(-1)\n","\n","                jacobians = torch.cat([jacobians, ite_jacobians], dim=1)\n","                offsets = torch.cat([offsets, ite_offsets], dim=1)\n","\n","            if self.dense:\n","                cur_embed = torch.cat((cur_embed, next_embed), 1)\n","            else:\n","                cur_embed = next_embed\n","\n","        leaf_input = torch.cat([jacobians, offsets.unsqueeze(-1)], dim=2).view(batch_size, -1)\n","        for i in range(self.num_back_layer):\n","            leaf_input = F.relu(self.backward_layer[i](leaf_input))\n","        leaf_output = self.backward_layer[-1](leaf_input)\n","\n","        return leaf_output, relu_masks"],"metadata":{"id":"-5AmSj4lzmpp","executionInfo":{"status":"ok","timestamp":1692979093473,"user_tz":-60,"elapsed":11,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["# 2. LCN utils"],"metadata":{"id":"eLYG6KXkYs1m"}},{"cell_type":"code","source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def print_args(args):\n","    print(\"\\nParameters:\")\n","    for attr, value in sorted(args.__dict__.items()):\n","        print(\"\\t{}={}\".format(attr.upper(), value))"],"metadata":{"id":"S4MIlQ2tX9Xg","executionInfo":{"status":"ok","timestamp":1692979093473,"user_tz":-60,"elapsed":10,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# 3. LCN Test"],"metadata":{"id":"VlSqjhUHYzn6"}},{"cell_type":"code","source":["def train(args, model, device, train_loader, optimizer, epoch, anneal, alpha=1):\n","    model.train()\n","    dataset_len = 0\n","    avg_loss = AverageMeter()\n","\n","    for (data, target) in train_loader:\n","        dataset_len += len(target)\n","        data, target = data.to(device), target.to(device)\n","        if args.task == 'classification':\n","            target = target.type(torch.cuda.LongTensor)\n","\n","        optimizer.zero_grad()\n","        ###############\n","        data.requires_grad = True\n","        if model.net_type == 'locally_constant':\n","            if args.p != -1:\n","                assert(args.p >= 0. and args.p < 1)\n","                output, regularization = model(data, alpha=alpha, anneal=anneal, p=args.p, training=True)\n","            else:\n","                output, regularization = model(data, alpha=alpha, anneal=anneal, p=1-alpha, training=True)\n","\n","        elif model.net_type == 'locally_linear':\n","            output, regularization = model.normal_forward(data)\n","        ###############\n","\n","        optimizer.zero_grad()\n","        if args.task == 'classification':\n","            loss = F.cross_entropy(output, target)\n","        elif args.task == 'regression':\n","            output = output.squeeze(-1)\n","            loss = ((output - target) ** 2).mean()\n","\n","        loss.backward()\n","        optimizer.step()\n","        avg_loss.update(loss.item())\n","\n","    return avg_loss.avg\n","\n","def test(args, model, device, test_loader, test_set_name):\n","    with torch.no_grad():\n","        model.eval()\n","        test_loss = 0\n","        correct = 0\n","\n","        score = []\n","        label = []\n","        dataset_len = 0\n","\n","        pattern_to_pred = dict()\n","        tree_x = []\n","        tree_pattern = []\n","\n","        for data, target in test_loader:\n","            dataset_len += len(target)\n","            label += list(target)\n","            data, target = data.to(device), target.to(device)\n","            if args.task == 'classification':\n","                target = target.type(torch.cuda.LongTensor)\n","\n","            ###############\n","            data.requires_grad = True\n","            if model.net_type == 'locally_constant':\n","                output, relu_masks = model(data, p=0, training=False)\n","            elif model.net_type == 'locally_linear':\n","                output, relu_masks = model.normal_forward(data, p=0, training=False)\n","            ###############\n","\n","            if args.task == 'classification':\n","                test_loss += F.cross_entropy(output, target, reduction='sum').item()\n","                output = torch.softmax(output, dim=-1)\n","                score += list(output[:, 1].cpu().data.numpy())\n","                pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n","                correct += pred.eq(target.view_as(pred)).sum().item()\n","                output = output[:, 1]\n","            elif args.task == 'regression':\n","                output = output.squeeze(-1)\n","                test_loss += ((output - target) ** 2).mean().item() * len(target)\n","\n","        test_loss /= dataset_len\n","        if args.task == 'classification':\n","            if args.output_dim == 2:\n","                AUC = roc_auc_score(label, score)\n","                test_score = AUC\n","            else:\n","                AUC = -1\n","                test_score = correct / dataset_len\n","\n","        elif args.task == 'regression':\n","            RMSE = np.sqrt(test_loss)\n","            test_score = -RMSE\n","\n","        return test_loss, test_score\n"],"metadata":{"id":"mL-qoJWeZF_f","executionInfo":{"status":"ok","timestamp":1692979093473,"user_tz":-60,"elapsed":9,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# 4. LCN Main"],"metadata":{"id":"aBgpmCRiZsGz"}},{"cell_type":"code","source":["def get_alpha(epoch, total_epoch):\n","    return float(epoch) / float(total_epoch)\n","\n","def main():\n","    # from some github repo...\n","    torch.multiprocessing.set_sharing_strategy('file_system')\n","\n","    args = get_args()\n","    use_cuda = not args.no_cuda and torch.cuda.is_available()\n","\n","    torch.manual_seed(args.seed)\n","    np.random.seed(args.seed)\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    train_loader, valid_loader, test_loader = get_data_loaders(args.dataset, args.batch_size, sub_task=args.sub_task, dim=args.input_dim)\n","\n","    if args.dataset in ['sider_split/', 'tox21_split/']:\n","        args.dataset = args.dataset[:-1] + '-' + str(args.sub_task)\n","\n","    print('batch number: train={}, valid={}, test={}'.format(len(train_loader), len(valid_loader), len(test_loader)))\n","\n","    model = Net(input_dim=args.input_dim, output_dim=args.output_dim, hidden_dim=args.hidden_dim, num_layer=args.depth, num_back_layer=args.back_n, dense=True, drop_type=args.drop_type, net_type=args.net_type, approx=args.anneal).to(device)\n","\n","    if args.optimizer == 'SGD':\n","        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, nesterov=True)\n","    elif args.optimizer == 'AMSGrad':\n","        optimizer = optim.Adam(model.parameters(), lr=args.lr, amsgrad=True)\n","    scheduler = StepLR(optimizer, step_size=args.lr_step_size, gamma=args.gamma)\n","\n","    best_score = -1e30\n","    start_epoch = 1  # start from epoch 1 or last checkpoint epoch\n","    if args.anneal == 'approx':\n","        args.net_type = 'approx_' + args.net_type\n","\n","\n","    best_model_name = './checkpoint/{}/{}/best_seed{}_depth{}_ckpt.t7'.format(args.dataset.strip('/'), args.net_type, args.seed, args.depth)\n","    last_model_name = './checkpoint/{}/{}/last_seed{}_depth{}_ckpt.t7'.format(args.dataset.strip('/'), args.net_type, args.seed, args.depth)\n","\n","    best_log_file = 'log/' + args.dataset.strip('/') + '/{}/depth{}_backn{}_drop{}_p{}_best.log'.format(args.net_type, args.depth, args.back_n, args.drop_type, args.p)\n","    last_log_file = 'log/' + args.dataset.strip('/') + '/{}/depth{}_backn{}_drop{}_p{}_last.log'.format(args.net_type, args.depth, args.back_n, args.drop_type, args.p)\n","\n","    model_dir = './checkpoint/{}/{}/'.format(args.dataset.strip('/'), args.net_type)\n","    if not os.path.exists(model_dir):\n","        os.makedirs(model_dir)\n","    log_dir = 'log/' + args.dataset.strip('/') + '/{}/'.format(args.net_type)\n","    if not os.path.exists(log_dir):\n","        os.makedirs(log_dir)\n","\n","    if not os.path.isdir('checkpoint'):\n","        os.mkdir('checkpoint')\n","\n","    for epoch in range(start_epoch, args.epochs + start_epoch):\n","        scheduler.step(epoch)\n","\n","        alpha = get_alpha(epoch, args.epochs)\n","        train_approximate_loss = train(args, model, device, train_loader, optimizer, epoch, args.anneal, alpha)\n","\n","        # used for plotting learning curves\n","        train_loss, train_score = test(args, model, device, train_loader, 'train')\n","        valid_loss, valid_score = test(args, model, device, valid_loader, 'valid')\n","        test_loss, test_score = test(args, model, device, test_loader, 'test')\n","\n","        # early stopping version\n","        if valid_score > best_score:\n","            state = {'model': model.state_dict()}\n","            torch.save(state, best_model_name)\n","            best_score = valid_score\n","\n","        # \"convergent\" version\n","        state = {'model': model.state_dict()}\n","        torch.save(state, last_model_name)\n","\n","    print('Training finished. Loading models from validation...')\n","    for model_name, log_file, setting in zip([best_model_name, last_model_name], [best_log_file, last_log_file], ['best', 'last']):\n","        print('\\nLoading the {} model...'.format(setting))\n","\n","        checkpoint = torch.load(model_name)\n","        model.load_state_dict(checkpoint['model'])\n","        train_loss, train_score = test(args, model, device, train_loader, 'train')\n","        valid_loss, valid_score = test(args, model, device, valid_loader, 'valid')\n","        test_loss, test_score = test(args, model, device, test_loader, 'test ')\n","\n","        with open(log_file, 'a') as fp:\n","            if args.task == 'classification':\n","                log_str = '{}\\t{:.4f}\\t{:.4f}\\t{:.4f}'.format(args.seed, train_score, valid_score, test_score)\n","            elif args.task == 'regression':\n","                log_str = '{}\\t{:.4f}\\t{:.4f}\\t{:.4f}'.format(args.seed, -train_score, -valid_score, -test_score)\n","            fp.write(log_str+'\\n')\n"],"metadata":{"id":"Ck1e9hNGZtj7","executionInfo":{"status":"ok","timestamp":1692979093473,"user_tz":-60,"elapsed":9,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# 5. LCN custom training loop"],"metadata":{"id":"XezqrpZxaKdn"}},{"cell_type":"code","source":["from NNTraining import *\n","\n","print('==== Begin run:====')\n","print('---- Initialising parameters for the run ----')\n","run_info = ex.begin_run_sticky()\n","\n","use_cuda = not args.no_cuda and torch.cuda.is_available()\n","torch.manual_seed(args.seed)\n","np.random.seed(args.seed)\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","args = Hyperparams(**run_info.get('hyp')) # hyperparameters for LCN need to be in form of an object (you can ignore this)\n","\n","print('---- Loading datasets ----')\n","X, y, categorical_indicator, attribute_names = ex.opml_load_task(run_info['mtpair_task'])\n","train_data, test_data, input_dim, output_dim = get_train_test(X, y, categorical_indicator, attribute_names, 0.75, args.seed) # Returns CustomDataset obj instances\n","\n","\n","DataLoadersIter = kfold_dataloader_iterator(train_data, # train_data needs to be an instance of CustomDataset\n","                                            n_splits= 5,\n","                                            random_state= args.seed,\n","                                            batch_size= args.batch_size,\n","                                            shuffle_kfold= True,\n","                                            shuffle_dataloader= True)\n","\n","test_dataloader = torch.utils.data.DataLoader(test_data, # CustomDataset obj can be directly passed to dataloader\n","                                              batch_size=len(test_data),\n","                                              shuffle= True)\n","\n","for kfold, (train_dataloader, val_dataloader) in enumerate(DataLoadersIter):\n","  print(f\"==== {kfold}th kfold sweep starting ====\")\n","\n","  model = Net(input_dim= input_dim, output_dim= output_dim,\n","              hidden_dim=args.hidden_dim,\n","              num_layer=args.depth,\n","              num_back_layer=args.back_n,\n","              dense=True,\n","              drop_type=args.drop_type,\n","              net_type=args.net_type,\n","              approx=args.anneal).to(device)\n","\n","\n","  if args.optimizer == 'SGD':\n","    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, nesterov=True)\n","  elif args.optimizer == 'AMSGrad':\n","    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, amsgrad=True)\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.lr_step_size, gamma=args.gamma)\n","\n","\n","\n","  start_epoch = 1  # start from epoch 1 or last checkpoint epoch\n","  if args.anneal == 'approx':\n","    args.net_type = 'approx_' + args.net_type\n","\n","\n","  for epoch in range(start_epoch, args.epochs + start_epoch):\n","      print(f\"----{epoch}th training epoch ----\")\n","      scheduler.step(epoch)\n","\n","      alpha = get_alpha(epoch, args.epochs)\n","      train_approximate_loss = train(args, model, device, train_dataloader, optimizer, epoch, args.anneal, alpha)\n","\n","      print(f'train_approximate_loss = {train_approximate_loss}')\n","\n","\n","      train_loss, train_score = test(args, model, device, train_dataloader, 'train')\n","      val_loss, val_score = test(args, model, device, val_dataloader, 'valid')\n","      test_loss, test_score = test(args, model, device, test_dataloader, 'test')\n","\n","      print(f'train_loss = {train_loss}, train_score = {train_score}')\n","      print(f'valid_loss = {val_loss}, valid_score = {val_score}')\n","      print(f'test_loss = {test_loss}, test_score = {test_score}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"altcS6fzaJ7T","executionInfo":{"status":"error","timestamp":1692979101887,"user_tz":-60,"elapsed":8422,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"64ba2cf6-88c5-4462-f4ec-473f6d7f86d1"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["==== Begin run:====\n","---- Initialising parameters for the run ----\n","{'_id': '64e8cf9565d03dc6054f2a52', 'metrics_per_epoch': [], 'experiment_id': '64e8b63efce6fc1c40c38231', 'experiment_name': 'Testing_LCN_4', 'mtpair_index': 158, 'mtpair_model': 'LLN_cls_SGD', 'mtpair_task': '337-361062', 'is_completed': False, 'user_id': '64d3a7457658d6ec6db139d0', 'user_name': 'bart', 'hyp': {'depth': 4, 'seed': 42, 'drop_type': 'none', 'p': 0, 'ensemble_n': 1, 'shrinkage': 1, 'back_n': 1, 'net_type': 'locally_linear', 'hidden_dim': 1, 'anneal': 'interpolation', 'optimizer': 'SGD', 'batch_size': 32, 'epochs': 90, 'lr': 0.07754428938436567, 'momentum': 0.9, 'no_cuda': False, 'lr_step_size': 10, 'gamma': 0.1, 'task': 'classification'}, 'model': 'LLN_cls_SGD', 'task': '337-361062'}\n","4e8cf9565d03dc6054f2a5\n","---- Loading datasets ----\n","downloading task 337-361062\n","using values from previous task load, skipped download\n","==== 0th kfold sweep starting ====\n","----1th training epoch ----\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-9f659419cf5a>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m       \u001b[0mtrain_approximate_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manneal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'train_approximate_loss = {train_approximate_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-3755902030bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch, anneal, alpha)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAverageMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mdataset_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/NNTraining/LcnAutomatedTraining.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mabsolute_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabsolute_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/NNTraining/LcnAutomatedTraining.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# print(f'Debuging x,y types: {type(x)}, {type(y)}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"]}]},{"cell_type":"code","source":["# from NNTraining import *\n","\n","# print('==== Begin run:====')\n","# print('---- Initialising parameters for the run ----')\n","# run_info = ex.begin_run_sticky()\n","\n","# use_cuda = not args.no_cuda and torch.cuda.is_available()\n","# torch.manual_seed(args.seed)\n","# np.random.seed(args.seed)\n","# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","# args = Hyperparams(**run_info.get('hyp')) # hyperparameters for LCN need to be in form of an object (you can ignore this)\n","\n","# print('---- Loading datasets ----')\n","# X, y, categorical_indicator, attribute_names = ex.opml_load_task(run_info['mtpair_task'])\n","# train_data, test_data, input_dim, output_dim = get_train_test(X, y, categorical_indicator, attribute_names, 0.75, args.seed) # Returns CustomDataset obj instances\n","\n","\n","# DataLoadersIter = kfold_dataloader_iterator(train_data, # train_data needs to be an instance of CustomDataset\n","#                                             n_splits= 5,\n","#                                             random_state= args.seed,\n","#                                             batch_size= args.batch_size,\n","#                                             shuffle_kfold= True,\n","#                                             shuffle_dataloader= True)\n","\n","# test_dataloader = torch.utils.data.DataLoader(test_data, # CustomDataset obj can be directly passed to dataloader\n","#                                               batch_size=len(test_data),\n","#                                               shuffle= True)\n","\n","# for kfold, (train_dataloader, val_dataloader) in enumerate(DataLoadersIter):\n","#   print(f\"==== {kfold}th kfold sweep starting ====\")\n","#   print(next(iter(train_dataloader)))"],"metadata":{"id":"vNq8JY_DwjkY","executionInfo":{"status":"aborted","timestamp":1692979101891,"user_tz":-60,"elapsed":16,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Reproducing errors:"],"metadata":{"id":"XIb9GKq0Y2Fv"}},{"cell_type":"code","source":["pred, out = next(iter(train_dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":912},"id":"QH8Vub1PBNc3","executionInfo":{"status":"error","timestamp":1692979161189,"user_tz":-60,"elapsed":413,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"cfcf8607-e6d0-489b-c291-983c104465c6"},"execution_count":21,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-d6f88ff1b0aa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/NNTraining/LcnAutomatedTraining.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mabsolute_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabsolute_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/NNTraining/LcnAutomatedTraining.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# print(f'Debuging x,y types: {type(x)}, {type(y)}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"]}]},{"cell_type":"code","source":["type(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFZ58DcOaNcp","executionInfo":{"status":"ok","timestamp":1692979178775,"user_tz":-60,"elapsed":4,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"d8e7a020-2342-4ff1-dc97-1f075fdca115"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.frame.DataFrame"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["type(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7HbvA9dbCkW","executionInfo":{"status":"ok","timestamp":1692979184310,"user_tz":-60,"elapsed":4,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"3abb7e82-c88b-4182-dc86-623e5055737e"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.series.Series"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e715iBvcbDqB","executionInfo":{"status":"ok","timestamp":1692979190031,"user_tz":-60,"elapsed":5,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"87de1385-7525-44f3-f6a9-d727f3993956"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        N\n","1        N\n","2        N\n","3        N\n","4        N\n","        ..\n","10077    P\n","10078    P\n","10079    P\n","10080    P\n","10081    P\n","Name: binaryClass, Length: 10082, dtype: category\n","Categories (2, object): ['N' < 'P']"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["df = y.to_frame()\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"no1Nb-I6bFKI","executionInfo":{"status":"ok","timestamp":1692979562411,"user_tz":-60,"elapsed":10,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"66ea0870-7100-47da-e801-c3ced141c592"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      binaryClass\n","0               N\n","1               N\n","2               N\n","3               N\n","4               N\n","...           ...\n","10077           P\n","10078           P\n","10079           P\n","10080           P\n","10081           P\n","\n","[10082 rows x 1 columns]"],"text/html":["\n","  <div id=\"df-eebad696-030b-4ef4-93c6-1c47070c7a17\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>binaryClass</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10077</th>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>10078</th>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>10079</th>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>10080</th>\n","      <td>P</td>\n","    </tr>\n","    <tr>\n","      <th>10081</th>\n","      <td>P</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10082 rows × 1 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eebad696-030b-4ef4-93c6-1c47070c7a17')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-eebad696-030b-4ef4-93c6-1c47070c7a17 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-eebad696-030b-4ef4-93c6-1c47070c7a17');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8993cfd9-d1d6-4175-8c91-e6f257f3a861\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8993cfd9-d1d6-4175-8c91-e6f257f3a861')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8993cfd9-d1d6-4175-8c91-e6f257f3a861 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["torch.tensor(df[5].values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":504},"id":"nff-vy_ObF6R","executionInfo":{"status":"error","timestamp":1692979586053,"user_tz":-60,"elapsed":390,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"8293373d-2501-420a-f5ae-db6846ec06e5"},"execution_count":32,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 5","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-2a6733fa6c54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 5"]}]},{"cell_type":"code","source":["run_info"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hhmdMW2xb3He","executionInfo":{"status":"ok","timestamp":1692979689173,"user_tz":-60,"elapsed":422,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"9e8d6599-6090-43dc-be68-b0eb78a0b58d"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'_id': '64e8cf9565d03dc6054f2a52',\n"," 'metrics_per_epoch': [],\n"," 'experiment_id': '64e8b63efce6fc1c40c38231',\n"," 'experiment_name': 'Testing_LCN_4',\n"," 'mtpair_index': 158,\n"," 'mtpair_model': 'LLN_cls_SGD',\n"," 'mtpair_task': '337-361062',\n"," 'is_completed': False,\n"," 'user_id': '64d3a7457658d6ec6db139d0',\n"," 'user_name': 'bart',\n"," 'hyp': {'depth': 4,\n","  'seed': 42,\n","  'drop_type': 'none',\n","  'p': 0,\n","  'ensemble_n': 1,\n","  'shrinkage': 1,\n","  'back_n': 1,\n","  'net_type': 'locally_linear',\n","  'hidden_dim': 1,\n","  'anneal': 'interpolation',\n","  'optimizer': 'SGD',\n","  'batch_size': 32,\n","  'epochs': 90,\n","  'lr': 0.07754428938436567,\n","  'momentum': 0.9,\n","  'no_cuda': False,\n","  'lr_step_size': 10,\n","  'gamma': 0.1,\n","  'task': 'classification'},\n"," 'model': 'LLN_cls_SGD',\n"," 'task': '337-361062'}"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["np.array(np.array(np.array([1]))).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXbiK1_yc8Xi","executionInfo":{"status":"ok","timestamp":1692979932646,"user_tz":-60,"elapsed":9,"user":{"displayName":"bartosz azaniux","userId":"12656151146140381527"}},"outputId":"f45d5ba0-7b81-4efa-b8e2-0248f2100ab5"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1,)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":[],"metadata":{"id":"NueXta1_dwFE"},"execution_count":null,"outputs":[]}]}