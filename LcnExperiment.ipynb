{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22311,
     "status": "ok",
     "timestamp": 1693527126975,
     "user": {
      "displayName": "bartosz azaniux",
      "userId": "12656151146140381527"
     },
     "user_tz": -60
    },
    "id": "hG3fkgsQBBCL",
    "outputId": "902e6808-21ae-4d46-fb4a-8ceb6bf74e5e",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drive version:\n",
    "# !pip uninstall TabularExperimentTrackerClient --y\n",
    "# !pip install git+https://github.com/DanielWarfield1/TabularExperimentTrackerClient\n",
    "# !pip uninstall NeuralNetworksTrainingPackage --y\n",
    "# !pip install git+https://github.com/Bartosz-G/NeuralNetworksTrainingPackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: NeuralNetworksTrainingPackage 1.0.0\n",
      "Uninstalling NeuralNetworksTrainingPackage-1.0.0:\n",
      "  Successfully uninstalled NeuralNetworksTrainingPackage-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Found existing installation: TabularExperimentTrackerClient 0.0.1\n",
      "Uninstalling TabularExperimentTrackerClient-0.0.1:\n",
      "  Successfully uninstalled TabularExperimentTrackerClient-0.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/DanielWarfield1/TabularExperimentTrackerClient\n",
      "  Cloning https://github.com/DanielWarfield1/TabularExperimentTrackerClient to /tmp/pip-req-build-v9pw718o\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/DanielWarfield1/TabularExperimentTrackerClient /tmp/pip-req-build-v9pw718o\n",
      "  Resolved https://github.com/DanielWarfield1/TabularExperimentTrackerClient to commit 5e738443d55b9637454776bd740a8083af70272d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: openml in /opt/conda/lib/python3.10/site-packages (from TabularExperimentTrackerClient==0.0.1) (0.14.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from TabularExperimentTrackerClient==0.0.1) (2.28.2)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from openml->TabularExperimentTrackerClient==0.0.1) (2.5.0)\n",
      "Requirement already satisfied: xmltodict in /opt/conda/lib/python3.10/site-packages (from openml->TabularExperimentTrackerClient==0.0.1) (0.13.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.10/site-packages (from openml->TabularExperimentTrackerClient==0.0.1) (1.2.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from openml->TabularExperimentTrackerClient==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from openml->TabularExperimentTrackerClient==0.0.1) (2.0.1)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /opt/conda/lib/python3.10/site-packages (from openml->TabularExperimentTrackerClient==0.0.1) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from openml->TabularExperimentTrackerClient==0.0.1) (1.23.5)\n",
      "Requirement already satisfied: minio in /opt/conda/lib/python3.10/site-packages (from openml->TabularExperimentTrackerClient==0.0.1) (7.1.16)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from openml->TabularExperimentTrackerClient==0.0.1) (12.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->TabularExperimentTrackerClient==0.0.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->TabularExperimentTrackerClient==0.0.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->TabularExperimentTrackerClient==0.0.1) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->TabularExperimentTrackerClient==0.0.1) (2023.5.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->openml->TabularExperimentTrackerClient==0.0.1) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->openml->TabularExperimentTrackerClient==0.0.1) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil->openml->TabularExperimentTrackerClient==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18->openml->TabularExperimentTrackerClient==0.0.1) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18->openml->TabularExperimentTrackerClient==0.0.1) (3.1.0)\n",
      "Building wheels for collected packages: TabularExperimentTrackerClient\n",
      "  Building wheel for TabularExperimentTrackerClient (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for TabularExperimentTrackerClient: filename=TabularExperimentTrackerClient-0.0.1-py3-none-any.whl size=6408 sha256=f928b094cc21a19a02d694eecdf206dc29b97d3b6f390d924c2c1f914f933c34\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dkp5kjl8/wheels/f9/2e/f3/69345202c956e07475c8f2f55074ad4d97b3e6a976b70fafab\n",
      "Successfully built TabularExperimentTrackerClient\n",
      "Installing collected packages: TabularExperimentTrackerClient\n",
      "Successfully installed TabularExperimentTrackerClient-0.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/Bartosz-G/NeuralNetworksTrainingPackage\n",
      "  Cloning https://github.com/Bartosz-G/NeuralNetworksTrainingPackage to /tmp/pip-req-build-v931wm0j\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/Bartosz-G/NeuralNetworksTrainingPackage /tmp/pip-req-build-v931wm0j\n",
      "  Resolved https://github.com/Bartosz-G/NeuralNetworksTrainingPackage to commit c013cb3a6013091549f5b6357d9360e405f134a5\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from NeuralNetworksTrainingPackage==1.0.0) (1.23.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from NeuralNetworksTrainingPackage==1.0.0) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from NeuralNetworksTrainingPackage==1.0.0) (1.2.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from NeuralNetworksTrainingPackage==1.0.0) (2.0.0)\n",
      "Requirement already satisfied: torcheval in /opt/conda/lib/python3.10/site-packages (from NeuralNetworksTrainingPackage==1.0.0) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->NeuralNetworksTrainingPackage==1.0.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->NeuralNetworksTrainingPackage==1.0.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->NeuralNetworksTrainingPackage==1.0.0) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->NeuralNetworksTrainingPackage==1.0.0) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->NeuralNetworksTrainingPackage==1.0.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->NeuralNetworksTrainingPackage==1.0.0) (3.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->NeuralNetworksTrainingPackage==1.0.0) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->NeuralNetworksTrainingPackage==1.0.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->NeuralNetworksTrainingPackage==1.0.0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->NeuralNetworksTrainingPackage==1.0.0) (1.3.0)\n",
      "Building wheels for collected packages: NeuralNetworksTrainingPackage\n",
      "  Building wheel for NeuralNetworksTrainingPackage (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for NeuralNetworksTrainingPackage: filename=NeuralNetworksTrainingPackage-1.0.0-py3-none-any.whl size=10233 sha256=28e11f68cddb6b8c7e4424b437812aed82412e993f01235cc85225266a4c37fa\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9wg58r_d/wheels/82/01/e8/da81de869be2f6b8c193a6fc5c42ee3ff0b6b97a7b70cd565a\n",
      "Successfully built NeuralNetworksTrainingPackage\n",
      "Installing collected packages: NeuralNetworksTrainingPackage\n",
      "Successfully installed NeuralNetworksTrainingPackage-1.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall NeuralNetworksTrainingPackage --y\n",
    "%pip uninstall TabularExperimentTrackerClient --y\n",
    "%pip install git+https://github.com/DanielWarfield1/TabularExperimentTrackerClient\n",
    "%pip install git+https://github.com/Bartosz-G/NeuralNetworksTrainingPackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5858,
     "status": "ok",
     "timestamp": 1693527132821,
     "user": {
      "displayName": "bartosz azaniux",
      "userId": "12656151146140381527"
     },
     "user_tz": -60
    },
    "id": "jguLhhgFBSkE",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43635,
     "status": "ok",
     "timestamp": 1693527176450,
     "user": {
      "displayName": "bartosz azaniux",
      "userId": "12656151146140381527"
     },
     "user_tz": -60
    },
    "id": "xsHc3zlSCO7J",
    "outputId": "121cd4b8-d138-4d2f-a0dc-d0de85c48f65",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from TabularExperimentTrackerClient.ExperimentClient import ExperimentClient\n",
    "\n",
    "path =  '../creds/'\n",
    "creds_orch_file = \"creds-orch.txt\"\n",
    "creds_openml_file = \"creds-openml.txt\"\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(path, creds_orch_file), 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    orchname = lines[0].strip()\n",
    "    orchsecret = lines[1].strip()\n",
    "\n",
    "with open (os.path.join(path, creds_openml_file), \"r\") as myfile:\n",
    "    openMLAPIKey = myfile.read()\n",
    "\n",
    "ex = ExperimentClient(verbose = True)\n",
    "\n",
    "\n",
    "ex.define_orch_cred(orchname, orchsecret)\n",
    "ex.define_opml_cred(openMLAPIKey)\n",
    "\n",
    "# Colab version\n",
    "# ex.define_opml_cred_drive('/My Drive/research/non-homogenous-data/creds/creds-openml.txt')\n",
    "# ex.define_orch_cred_drive('bart', '/My Drive//research/non-homogenous-data/creds/creds-colab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBYDfcuJE-bP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Defining the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1693527176452,
     "user": {
      "displayName": "bartosz azaniux",
      "userId": "12656151146140381527"
     },
     "user_tz": -60
    },
    "id": "lyMEiU5ODM2e",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = 'test_LCN_6'\n",
    "\n",
    "\n",
    "\n",
    "# LCN and LLN Parameters\n",
    "depth = {'distribution': 'categorical', 'values':[2,3,4,5,6,7,8,9,10,11,12]}\n",
    "seed = {'distribution': 'constant', 'value': 42}\n",
    "drop_type = {'distribution': 'constant', 'value': 'isDropConnect'} # defined by p = 0 or p =/= 0\n",
    "p = {'distribution': 'categorical', 'values':[0, 0, 0.25, 0.5, 0.75]} # 40% probability of no regularisation\n",
    "hidden_dim = {'distribution': 'constant', 'value': 1} # Assertion error coming from Net if not 1\n",
    "anneal = {'distribution': 'constant', 'value': 'none'}\n",
    "optimizer = {'distribution': 'categorical', 'values': ['SGD', 'SGD', 'SGD', 'SGD', 'AMSGrad']} # 80% of SGD and 20% AMSGrad\n",
    "batch_size = {'distribution': 'constant', 'value': 64}\n",
    "epochs = {'distribution': 'constant', 'value': 30}\n",
    "lr = {'distribution': 'log_uniform', 'min':0.05, 'max':0.2} # yields mean = 0.1082, median 0.1\n",
    "momentum = {'distribution': 'constant', 'value': 0.9}\n",
    "no_cuda = {'distribution': 'constant', 'value': False}\n",
    "lr_step_size = {'distribution': 'constant', 'value': 10}\n",
    "gamma = {'distribution': 'constant', 'value': 0.1}\n",
    "\n",
    "# Regression:\n",
    "back_n_reg = {'distribution': 'categorical', 'values':[0, 1, 2, 3, 4]}\n",
    "\n",
    "# Classification:\n",
    "back_n_cls = {'distribution': 'constant', 'value': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1693527176453,
     "user": {
      "displayName": "bartosz azaniux",
      "userId": "12656151146140381527"
     },
     "user_tz": -60
    },
    "id": "3atPjhTUEn05",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#============================================================\n",
    "# Locally Constant Networks\n",
    "#============================================================\n",
    "LCN_reg_space = {\n",
    "    'depth': depth,\n",
    "    'seed': seed,\n",
    "    'drop_type': drop_type,\n",
    "    'p': p,\n",
    "    'ensemble_n': {'distribution': 'constant', 'value': 1},\n",
    "    'shrinkage': {'distribution': 'constant', 'value': 1},\n",
    "    'back_n': back_n_reg,\n",
    "    'net_type': {'distribution': 'constant', 'value': 'locally_constant'},\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'anneal': anneal,\n",
    "    'optimizer': optimizer,\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "    'lr': lr,\n",
    "    'momentum': momentum,\n",
    "    'no_cuda': no_cuda,\n",
    "    'lr_step_size': lr_step_size,\n",
    "    'gamma': gamma,\n",
    "    'task': {'distribution': 'constant', 'value': 'regression'}\n",
    "    }\n",
    "\n",
    "LCN_cls_space = {\n",
    "    'depth': depth,\n",
    "    'seed': seed,\n",
    "    'drop_type': drop_type,\n",
    "    'p': p,\n",
    "    'ensemble_n': {'distribution': 'constant', 'value': 1},\n",
    "    'shrinkage': {'distribution': 'constant', 'value': 1},\n",
    "    'back_n': back_n_cls,\n",
    "    'net_type': {'distribution': 'constant', 'value': 'locally_constant'},\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'anneal': anneal,\n",
    "    'optimizer': optimizer,\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "    'lr': lr,\n",
    "    'momentum': momentum,\n",
    "    'no_cuda': no_cuda,\n",
    "    'lr_step_size': lr_step_size,\n",
    "    'gamma': gamma,\n",
    "    'task': {'distribution': 'constant', 'value': 'classification'}\n",
    "}\n",
    "\n",
    "#============================================================\n",
    "# Locally Linear Networks\n",
    "#============================================================\n",
    "\n",
    "LLN_reg_space = {\n",
    "    'depth': depth,\n",
    "    'seed': seed,\n",
    "    'drop_type': drop_type,\n",
    "    'p': p,\n",
    "    'ensemble_n': {'distribution': 'constant', 'value': 1},\n",
    "    'shrinkage': {'distribution': 'constant', 'value': 1},\n",
    "    'back_n': back_n_reg,\n",
    "    'net_type': {'distribution': 'constant', 'value': 'locally_linear'},\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'anneal': anneal,\n",
    "    'optimizer': optimizer,\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "    'lr': lr,\n",
    "    'momentum': momentum,\n",
    "    'no_cuda': no_cuda,\n",
    "    'lr_step_size': lr_step_size,\n",
    "    'gamma': gamma,\n",
    "    'task': {'distribution': 'constant', 'value': 'regression'}\n",
    "    }\n",
    "\n",
    "\n",
    "LLN_cls_space = {\n",
    "    'depth': depth,\n",
    "    'seed': seed,\n",
    "    'drop_type': drop_type,\n",
    "    'p': p,\n",
    "    'ensemble_n': {'distribution': 'constant', 'value': 1},\n",
    "    'shrinkage': {'distribution': 'constant', 'value': 1},\n",
    "    'back_n': back_n_cls,\n",
    "    'net_type': {'distribution': 'constant', 'value': 'locally_linear'},\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'anneal': anneal,\n",
    "    'optimizer': optimizer,\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "    'lr': lr,\n",
    "    'momentum': momentum,\n",
    "    'no_cuda': no_cuda,\n",
    "    'lr_step_size': lr_step_size,\n",
    "    'gamma': gamma,\n",
    "    'task': {'distribution': 'constant', 'value': 'classification'}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1693527176453,
     "user": {
      "displayName": "bartosz azaniux",
      "userId": "12656151146140381527"
     },
     "user_tz": -60
    },
    "id": "5UI-B-EbEJUh",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_groups = {\n",
    "    'LCN_reg':{'model':'LCN_reg', 'hype':LCN_reg_space},\n",
    "    'LCN_cls':{'model':'LCN_cls', 'hype':LCN_cls_space},\n",
    "    'LLN_reg':{'model':'LLN_reg', 'hype':LLN_reg_space},\n",
    "    'LLN_cls':{'model':'LLN_cls', 'hype':LLN_cls_space}\n",
    "}\n",
    "\n",
    "ex.def_model_groups(model_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1693527178212,
     "user": {
      "displayName": "bartosz azaniux",
      "userId": "12656151146140381527"
     },
     "user_tz": -60
    },
    "id": "BFVftUr4EMSr",
    "outputId": "096cceb4-bd60-4c4c-f052-fc8967518e9f",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatically defined data groups: dict_keys(['opml_reg_purnum_group', 'opml_class_purnum_group', 'opml_reg_numcat_group', 'opml_class_numcat_group'])\n",
      "existing experiment found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'existing experiment found'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.def_data_groups_opml()\n",
    "print(f'automatically defined data groups: {ex.data_groups.keys()}')\n",
    "\n",
    "classification_models = [k for k in model_groups.keys() if '_cls' in k]\n",
    "regression_models = [k for k in model_groups.keys() if '_reg' in k]\n",
    "\n",
    "\n",
    "applications = {'opml_reg_purnum_group': regression_models,\n",
    "                'opml_reg_numcat_group': regression_models,\n",
    "                'opml_class_purnum_group': classification_models,\n",
    "                'opml_class_numcat_group': classification_models}\n",
    "\n",
    "ex.def_applications(applications)\n",
    "ex.reg_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1693527178723,
     "user": {
      "displayName": "bartosz azaniux",
      "userId": "12656151146140381527"
     },
     "user_tz": -60
    },
    "id": "-I95Kh4qMo1u",
    "outputId": "db2495fa-b945-4480-e310-32f6e368c0c3",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total required runs: 7080\n"
     ]
    }
   ],
   "source": [
    "exp_info = ex.experiment_info()\n",
    "successful_runs = exp_info['successful_runs']\n",
    "required_runs = exp_info['required_runs']\n",
    "print('total required runs: {}'.format(required_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLkZmpB9yVys",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. General Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NeuralNetworksTrainingPackage.event_handler import dataPreProcessingEventEmitter\n",
    "from NeuralNetworksTrainingPackage.dataprocessing.basic_pre_processing import filterCardinality, quantileTransform, truncateData ,balancedTruncateData, oneHotEncodePredictors, oneHotEncodeTargets, toDataFrame, splitTrainValTest, balancedSplitTrainValTest\n",
    "\n",
    "n_sample = 20000\n",
    "split = [0.5, 0.25, 0.25]\n",
    "quantile_transform_distribution='normal'\n",
    "\n",
    "\n",
    "data_pre_processing = dataPreProcessingEventEmitter()\n",
    "\n",
    "filter_cardinality = filterCardinality(transform = 'all')\n",
    "truncate_data = truncateData(n = n_sample, transform = 'all')\n",
    "balanced_truncate_data = balancedTruncateData(n = n_sample, transform = 'all') # Ensures balance of classes\n",
    "one_hot_encode_predictors = oneHotEncodePredictors(transform = 'all')\n",
    "one_hot_encode_targets = oneHotEncodeTargets(transform = 'all')\n",
    "to_data_frame = toDataFrame(transform = 'all')\n",
    "split_train_val_test = splitTrainValTest(split = split)\n",
    "balanced_split_train_val_test = balancedSplitTrainValTest(split = split)\n",
    "quantile_transform = quantileTransform(output_distribution = quantile_transform_distribution, transform = 'all')\n",
    "\n",
    "\n",
    "# Transformations will be called in the order they're added to data_pre_processing\n",
    "data_pre_processing.add_pre_processing_step('regression', filter_cardinality)\n",
    "data_pre_processing.add_pre_processing_step('regression', truncate_data)\n",
    "data_pre_processing.add_pre_processing_step('regression', one_hot_encode_predictors)\n",
    "data_pre_processing.add_pre_processing_step('regression', to_data_frame)\n",
    "data_pre_processing.add_pre_processing_step('regression', split_train_val_test)\n",
    "data_pre_processing.add_pre_processing_step('regression', quantile_transform)\n",
    "\n",
    "\n",
    "data_pre_processing.add_pre_processing_step('classification', filter_cardinality)\n",
    "data_pre_processing.add_pre_processing_step('classification', balanced_truncate_data)\n",
    "data_pre_processing.add_pre_processing_step('classification', one_hot_encode_predictors)\n",
    "data_pre_processing.add_pre_processing_step('classification', one_hot_encode_targets)\n",
    "data_pre_processing.add_pre_processing_step('classification', to_data_frame)\n",
    "data_pre_processing.add_pre_processing_step('classification', balanced_split_train_val_test)\n",
    "data_pre_processing.add_pre_processing_step('classification', quantile_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Model Specific Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from NeuralNetworksTrainingPackage.dataprocessing.basic_pre_processing import CustomDataset, toPyTorchDatasets\n",
    "\n",
    "to_pytorch_datasets = toPyTorchDatasets(wrapper = CustomDataset)\n",
    "\n",
    "# Transformations will be called after general pre-processing steps, and in order they're added\n",
    "data_pre_processing.add_pre_processing_step('LCN_reg', to_pytorch_datasets)\n",
    "\n",
    "data_pre_processing.add_pre_processing_step('LCN_cls', to_pytorch_datasets)\n",
    "\n",
    "data_pre_processing.add_pre_processing_step('LLN_reg', to_pytorch_datasets)\n",
    "\n",
    "data_pre_processing.add_pre_processing_step('LLN_cls', to_pytorch_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from metrics.LcnMetrics import LcnMetricsClassification, LcnMetricsRegression\n",
    "\n",
    "lcn_metrics_regression = LcnMetricsRegression()\n",
    "lcn_metrics_classification = LcnMetricsClassification()\n",
    "\n",
    "lcn_metrics = {'regression': lcn_metrics_regression,\n",
    "               'classification': lcn_metrics_classification}\n",
    "\n",
    "metric_model_pairs = {\n",
    "    'LCN_reg': lcn_metrics,\n",
    "    'LCN_cls': lcn_metrics,\n",
    "    'LLN_reg': lcn_metrics,\n",
    "    'LLN_cls': lcn_metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Model Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.LcnNetwork import init_LcnNetwork\n",
    "from training.LcnTrain import LcnTrainingRoutine\n",
    "\n",
    "lcn_model_and_training = {'model_init':init_LcnNetwork, 'training_routine': LcnTrainingRoutine}\n",
    "\n",
    "model_training_pairs = {\n",
    "    'LCN_reg': lcn_model_and_training,\n",
    "    'LCN_cls': lcn_model_and_training,\n",
    "    'LLN_reg': lcn_model_and_training,\n",
    "    'LNN_cls': lcn_model_and_training\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Main Experiment loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJKPv2m6nFzd",
    "outputId": "36bedcf2-a3b9-4b13-81f1-43c5b157c89f",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Begin run:0 ====\n",
      "{'error': '{\"message\":\"ObjectId in must be a single string of 12 bytes or a string of 24 hex characters\",\"name\":\"Error\"}', 'error_code': 'FunctionExecutionError', 'link': 'https://realm.mongodb.com/groups/64c03018b2c07a5e4ef40e59/apps/64c0314e1b6168a5423a9e14/logs?co_id=650b037579ad1ad5cca3dde8'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mtpair_task'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m14160\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m==== Begin run:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     run_info \u001b[38;5;241m=\u001b[39m \u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_run_sticky\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     hyperparameters \u001b[38;5;241m=\u001b[39m run_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m run_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/TabularExperimentTrackerClient/ExperimentClient.py:322\u001b[0m, in \u001b[0;36mExperimentClient.begin_run_sticky\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m currun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_run()\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m#updating sticky\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstuck_task \u001b[38;5;241m=\u001b[39m \u001b[43mcurrun\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmtpair_task\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_id[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mtpair_task'"
     ]
    }
   ],
   "source": [
    "torch_models = ('LCN_reg', 'LCN_cls', 'LLN_reg', 'LLN_cls')\n",
    "\n",
    "sklearn_models = ('no_sklearn_models_in_this_training')\n",
    "\n",
    "\n",
    "for i in range(14160):\n",
    "    print(f'==== Begin run:{i} ====')\n",
    "    run_info = ex.begin_run_sticky()\n",
    "\n",
    "    hyperparameters = run_info['hyp']\n",
    "    model_name = run_info['model']\n",
    "\n",
    "    task = hyperparameters['task']\n",
    "    seed = hyperparameters['seed']\n",
    "\n",
    "\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "    print('---- Loading datasets ----')\n",
    "    X, y, categorical_indicator, attribute_names = ex.opml_load_task(run_info['mtpair_task'])\n",
    "\n",
    "    # Pre-processing\n",
    "    data_pre_processing.set_seed_for_all(seed)\n",
    "    data_pre_processing.set_dataset(X, y, categorical_indicator, attribute_names)\n",
    "    data_pre_processing.apply(task)\n",
    "    data_pre_processing.apply(model_name)\n",
    "    train_data, val_data, test_data = data_pre_processing.get_train_val_test()\n",
    "\n",
    "\n",
    "    # Getting appropriate metrics\n",
    "    metrics_calculator = metric_model_pairs[model_name][task]\n",
    "\n",
    "\n",
    "    match model_name:\n",
    "        case _ if model_name in sklearn_models:\n",
    "            pass\n",
    "\n",
    "        case _ if model_name in torch_models:\n",
    "            # hyperparameters will be updated with {'input_dim': num_columns_X, 'output_dim':num_columns_Y}\n",
    "            hyperparameters.update(train_data.get_dims())\n",
    "\n",
    "            train_batch_size = hyperparameters['batch_size']\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=train_batch_size,shuffle= True)\n",
    "            val_dataloader = torch.utils.data.DataLoader(val_data,batch_size=len(val_data),shuffle= True)\n",
    "            test_dataloader = torch.utils.data.DataLoader(test_data,batch_size=len(test_data),shuffle= True)\n",
    "\n",
    "\n",
    "            init_model = model_training_pairs[model_name]['model_init']\n",
    "            TrainingRoutine = model_training_pairs[model_name]['training_routine']\n",
    "\n",
    "\n",
    "            model = init_model(**hyperparameters)\n",
    "            training_routine = TrainingRoutine(**hyperparameters)\n",
    "            \n",
    "            training_routine.set_optimizer_scheduler(model)\n",
    "\n",
    "            start_epoch = 1  # start from epoch 1 or last checkpoint epoch\n",
    "            total_epochs = hyperparameters['epochs']\n",
    "            start_time = time.time()\n",
    "\n",
    "            for epoch in range(start_epoch, total_epochs + start_epoch):\n",
    "                print(f\"----{epoch}th training epoch ----\")\n",
    "                epoch_metrics = {}\n",
    "\n",
    "                training_routine.scheduler_step(epoch)\n",
    "                train_loss = training_routine.train(model, train_dataloader)\n",
    "\n",
    "\n",
    "                if train_loss is None:\n",
    "                    print('---Stopping training due to loss being nan!---')\n",
    "                    epoch_metrics = {'train_loss': train_loss, 'epoch': epoch}\n",
    "                    ex.update_run(epoch_metrics)\n",
    "                    break\n",
    "\n",
    "                if epoch == total_epochs:\n",
    "                    continue\n",
    "\n",
    "                epoch_metrics.update(train_loss)\n",
    "                epoch_metrics.update({'epoch': epoch})\n",
    "                ex.update_run(epoch_metrics)\n",
    "                print(epoch_metrics)\n",
    "\n",
    "            else:\n",
    "                final_metrics = {}\n",
    "                training_time = time.time()-start_time\n",
    "\n",
    "                train_metrics = metrics_calculator.get_metrics(model, train_dataloader, hyperparameters, 'train')\n",
    "                val_all_metrics = metrics_calculator.get_all(model, val_dataloader, hyperparameters, 'val')\n",
    "                test_all_metrics = metrics_calculator.get_all(model, test_dataloader, hyperparameters, 'test')\n",
    "\n",
    "                final_metrics.update(train_loss)\n",
    "                final_metrics.update(train_metrics)\n",
    "                final_metrics.update(val_all_metrics)\n",
    "                final_metrics.update(test_all_metrics)\n",
    "                final_metrics.update({'epoch': epoch})\n",
    "                final_metrics.update({'epoch_time': training_time})\n",
    "\n",
    "                ex.update_run(final_metrics)\n",
    "                print(final_metrics)\n",
    "\n",
    "    ex.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsz24ztP9CQ8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Checking whether the code works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_models = ('LCN_reg', 'LCN_cls', 'LLN_reg', 'LLN_cls')\n",
    "\n",
    "sklearn_models = ('no_sklearn_models_in_this_training')\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    print(f'==== Begin run:{i} ====')\n",
    "    run_info = ex.begin_run()\n",
    "\n",
    "    hyperparameters = run_info['hyp']\n",
    "    model_name = run_info['model']\n",
    "\n",
    "    task = hyperparameters['task']\n",
    "    seed = hyperparameters['seed']\n",
    "\n",
    "\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "    print('---- Loading datasets ----')\n",
    "    X, y, categorical_indicator, attribute_names = ex.opml_load_task(run_info['mtpair_task'])\n",
    "\n",
    "    # Pre-processing\n",
    "    data_pre_processing.set_seed_for_all(seed)\n",
    "    data_pre_processing.set_dataset(X, y, categorical_indicator, attribute_names)\n",
    "    data_pre_processing.apply(task)\n",
    "    data_pre_processing.apply(model_name)\n",
    "    train_data, val_data, test_data = data_pre_processing.get_train_val_test()\n",
    "\n",
    "\n",
    "    # Getting appropriate metrics\n",
    "    metrics_calculator = metric_model_pairs[model_name][task]\n",
    "\n",
    "\n",
    "    match model_name:\n",
    "        case _ if model_name in sklearn_models:\n",
    "            pass\n",
    "\n",
    "        case _ if model_name in torch_models:\n",
    "            # hyperparameters will be updated with {'input_dim': num_columns_X, 'output_dim':num_columns_Y}\n",
    "            hyperparameters.update(train_data.get_dims())\n",
    "\n",
    "            train_batch_size = hyperparameters['batch_size']\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=train_batch_size,shuffle= True)\n",
    "            val_dataloader = torch.utils.data.DataLoader(val_data,batch_size=len(val_data),shuffle= True)\n",
    "            test_dataloader = torch.utils.data.DataLoader(test_data,batch_size=len(test_data),shuffle= True)\n",
    "\n",
    "\n",
    "            init_model = model_training_pairs[model_name]['model_init']\n",
    "            TrainingRoutine = model_training_pairs[model_name]['training_routine']\n",
    "\n",
    "\n",
    "            model = init_model(**hyperparameters)\n",
    "            training_routine = TrainingRoutine(**hyperparameters)\n",
    "            \n",
    "            training_routine.set_optimizer_scheduler(model)\n",
    "\n",
    "            start_epoch = 1  # start from epoch 1 or last checkpoint epoch\n",
    "            total_epochs = hyperparameters['epochs']\n",
    "            start_time = time.time()\n",
    "\n",
    "            for epoch in range(start_epoch, total_epochs + start_epoch):\n",
    "                print(f\"----{epoch}th training epoch ----\")\n",
    "                epoch_metrics = {}\n",
    "\n",
    "                training_routine.scheduler_step(epoch)\n",
    "                train_loss = training_routine.train(model, train_dataloader)\n",
    "\n",
    "\n",
    "                if train_loss is None:\n",
    "                    print('---Stopping training due to loss being nan!---')\n",
    "                    epoch_metrics = {'train_loss': train_loss, 'epoch': epoch}\n",
    "                    ex.update_run(epoch_metrics)\n",
    "                    break\n",
    "\n",
    "                if epoch == total_epochs:\n",
    "                    continue\n",
    "\n",
    "                epoch_metrics.update(train_loss)\n",
    "                epoch_metrics.update({'epoch': epoch})\n",
    "                ex.update_run(epoch_metrics)\n",
    "                print(epoch_metrics)\n",
    "\n",
    "            else:\n",
    "                final_metrics = {}\n",
    "                training_time = time.time()-start_time\n",
    "\n",
    "                train_metrics = metrics_calculator.get_metrics(model, train_dataloader, hyperparameters, 'train')\n",
    "                val_all_metrics = metrics_calculator.get_all(model, val_dataloader, hyperparameters, 'val')\n",
    "                test_all_metrics = metrics_calculator.get_all(model, test_dataloader, hyperparameters, 'test')\n",
    "\n",
    "                final_metrics.update(train_loss)\n",
    "                final_metrics.update(train_metrics)\n",
    "                final_metrics.update(val_all_metrics)\n",
    "                final_metrics.update(test_all_metrics)\n",
    "                final_metrics.update({'epoch': epoch})\n",
    "                final_metrics.update({'epoch_time': training_time})\n",
    "\n",
    "                ex.update_run(final_metrics)\n",
    "                print(final_metrics)\n",
    "\n",
    "    ex.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': '{\"message\":\"ObjectId in must be a single string of 12 bytes or a string of 24 hex characters\",\"name\":\"Error\"}', 'error_code': 'FunctionExecutionError', 'link': 'https://realm.mongodb.com/groups/64c03018b2c07a5e4ef40e59/apps/64c0314e1b6168a5423a9e14/logs?co_id=650b0405ba65216a4e32b2ec'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mtpair_task'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/TabularExperimentTrackerClient/ExperimentClient.py:300\u001b[0m, in \u001b[0;36mExperimentClient.begin_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m currun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_run()\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m#updating sticky\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstuck_task \u001b[38;5;241m=\u001b[39m \u001b[43mcurrun\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmtpair_task\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_id[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mtpair_task'"
     ]
    }
   ],
   "source": [
    "ex.begin_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'expname': 'test_LCN_6',\n",
       " 'model_groups': {'LCN_reg': {'model': 'LCN_reg',\n",
       "   'hype': {'depth': {'distribution': 'categorical',\n",
       "     'values': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]},\n",
       "    'seed': {'distribution': 'constant', 'value': 42},\n",
       "    'drop_type': {'distribution': 'constant', 'value': 'isDropConnect'},\n",
       "    'p': {'distribution': 'categorical', 'values': [0, 0, 0.25, 0.5, 0.75]},\n",
       "    'ensemble_n': {'distribution': 'constant', 'value': 1},\n",
       "    'shrinkage': {'distribution': 'constant', 'value': 1},\n",
       "    'back_n': {'distribution': 'categorical', 'values': [0, 1, 2, 3, 4]},\n",
       "    'net_type': {'distribution': 'constant', 'value': 'locally_constant'},\n",
       "    'hidden_dim': {'distribution': 'constant', 'value': 1},\n",
       "    'anneal': {'distribution': 'constant', 'value': 'none'},\n",
       "    'optimizer': {'distribution': 'categorical',\n",
       "     'values': ['SGD', 'SGD', 'SGD', 'SGD', 'AMSGrad']},\n",
       "    'batch_size': {'distribution': 'constant', 'value': 64},\n",
       "    'epochs': {'distribution': 'constant', 'value': 30},\n",
       "    'lr': {'distribution': 'log_uniform', 'min': 0.05, 'max': 0.2},\n",
       "    'momentum': {'distribution': 'constant', 'value': 0.9},\n",
       "    'no_cuda': {'distribution': 'constant', 'value': False},\n",
       "    'lr_step_size': {'distribution': 'constant', 'value': 10},\n",
       "    'gamma': {'distribution': 'constant', 'value': 0.1},\n",
       "    'task': {'distribution': 'constant', 'value': 'regression'}}},\n",
       "  'LCN_cls': {'model': 'LCN_cls',\n",
       "   'hype': {'depth': {'distribution': 'categorical',\n",
       "     'values': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]},\n",
       "    'seed': {'distribution': 'constant', 'value': 42},\n",
       "    'drop_type': {'distribution': 'constant', 'value': 'isDropConnect'},\n",
       "    'p': {'distribution': 'categorical', 'values': [0, 0, 0.25, 0.5, 0.75]},\n",
       "    'ensemble_n': {'distribution': 'constant', 'value': 1},\n",
       "    'shrinkage': {'distribution': 'constant', 'value': 1},\n",
       "    'back_n': {'distribution': 'constant', 'value': 0},\n",
       "    'net_type': {'distribution': 'constant', 'value': 'locally_constant'},\n",
       "    'hidden_dim': {'distribution': 'constant', 'value': 1},\n",
       "    'anneal': {'distribution': 'constant', 'value': 'none'},\n",
       "    'optimizer': {'distribution': 'categorical',\n",
       "     'values': ['SGD', 'SGD', 'SGD', 'SGD', 'AMSGrad']},\n",
       "    'batch_size': {'distribution': 'constant', 'value': 64},\n",
       "    'epochs': {'distribution': 'constant', 'value': 30},\n",
       "    'lr': {'distribution': 'log_uniform', 'min': 0.05, 'max': 0.2},\n",
       "    'momentum': {'distribution': 'constant', 'value': 0.9},\n",
       "    'no_cuda': {'distribution': 'constant', 'value': False},\n",
       "    'lr_step_size': {'distribution': 'constant', 'value': 10},\n",
       "    'gamma': {'distribution': 'constant', 'value': 0.1},\n",
       "    'task': {'distribution': 'constant', 'value': 'classification'}}},\n",
       "  'LLN_reg': {'model': 'LLN_reg',\n",
       "   'hype': {'depth': {'distribution': 'categorical',\n",
       "     'values': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]},\n",
       "    'seed': {'distribution': 'constant', 'value': 42},\n",
       "    'drop_type': {'distribution': 'constant', 'value': 'isDropConnect'},\n",
       "    'p': {'distribution': 'categorical', 'values': [0, 0, 0.25, 0.5, 0.75]},\n",
       "    'ensemble_n': {'distribution': 'constant', 'value': 1},\n",
       "    'shrinkage': {'distribution': 'constant', 'value': 1},\n",
       "    'back_n': {'distribution': 'categorical', 'values': [0, 1, 2, 3, 4]},\n",
       "    'net_type': {'distribution': 'constant', 'value': 'locally_linear'},\n",
       "    'hidden_dim': {'distribution': 'constant', 'value': 1},\n",
       "    'anneal': {'distribution': 'constant', 'value': 'none'},\n",
       "    'optimizer': {'distribution': 'categorical',\n",
       "     'values': ['SGD', 'SGD', 'SGD', 'SGD', 'AMSGrad']},\n",
       "    'batch_size': {'distribution': 'constant', 'value': 64},\n",
       "    'epochs': {'distribution': 'constant', 'value': 30},\n",
       "    'lr': {'distribution': 'log_uniform', 'min': 0.05, 'max': 0.2},\n",
       "    'momentum': {'distribution': 'constant', 'value': 0.9},\n",
       "    'no_cuda': {'distribution': 'constant', 'value': False},\n",
       "    'lr_step_size': {'distribution': 'constant', 'value': 10},\n",
       "    'gamma': {'distribution': 'constant', 'value': 0.1},\n",
       "    'task': {'distribution': 'constant', 'value': 'regression'}}},\n",
       "  'LLN_cls': {'model': 'LLN_cls',\n",
       "   'hype': {'depth': {'distribution': 'categorical',\n",
       "     'values': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]},\n",
       "    'seed': {'distribution': 'constant', 'value': 42},\n",
       "    'drop_type': {'distribution': 'constant', 'value': 'isDropConnect'},\n",
       "    'p': {'distribution': 'categorical', 'values': [0, 0, 0.25, 0.5, 0.75]},\n",
       "    'ensemble_n': {'distribution': 'constant', 'value': 1},\n",
       "    'shrinkage': {'distribution': 'constant', 'value': 1},\n",
       "    'back_n': {'distribution': 'constant', 'value': 0},\n",
       "    'net_type': {'distribution': 'constant', 'value': 'locally_linear'},\n",
       "    'hidden_dim': {'distribution': 'constant', 'value': 1},\n",
       "    'anneal': {'distribution': 'constant', 'value': 'none'},\n",
       "    'optimizer': {'distribution': 'categorical',\n",
       "     'values': ['SGD', 'SGD', 'SGD', 'SGD', 'AMSGrad']},\n",
       "    'batch_size': {'distribution': 'constant', 'value': 64},\n",
       "    'epochs': {'distribution': 'constant', 'value': 30},\n",
       "    'lr': {'distribution': 'log_uniform', 'min': 0.05, 'max': 0.2},\n",
       "    'momentum': {'distribution': 'constant', 'value': 0.9},\n",
       "    'no_cuda': {'distribution': 'constant', 'value': False},\n",
       "    'lr_step_size': {'distribution': 'constant', 'value': 10},\n",
       "    'gamma': {'distribution': 'constant', 'value': 0.1},\n",
       "    'task': {'distribution': 'constant', 'value': 'classification'}}}},\n",
       " 'data_groups': {'opml_reg_purnum_group': ['336-361072',\n",
       "   '336-361073',\n",
       "   '336-361074',\n",
       "   '336-361076',\n",
       "   '336-361077',\n",
       "   '336-361078',\n",
       "   '336-361079',\n",
       "   '336-361080',\n",
       "   '336-361081',\n",
       "   '336-361082',\n",
       "   '336-361083',\n",
       "   '336-361084',\n",
       "   '336-361085',\n",
       "   '336-361086',\n",
       "   '336-361087',\n",
       "   '336-361088',\n",
       "   '336-361279',\n",
       "   '336-361280',\n",
       "   '336-361281'],\n",
       "  'opml_class_purnum_group': ['337-361055',\n",
       "   '337-361060',\n",
       "   '337-361061',\n",
       "   '337-361062',\n",
       "   '337-361063',\n",
       "   '337-361065',\n",
       "   '337-361066',\n",
       "   '337-361068',\n",
       "   '337-361069',\n",
       "   '337-361070',\n",
       "   '337-361273',\n",
       "   '337-361274',\n",
       "   '337-361275',\n",
       "   '337-361276',\n",
       "   '337-361277',\n",
       "   '337-361278'],\n",
       "  'opml_reg_numcat_group': ['335-361093',\n",
       "   '335-361094',\n",
       "   '335-361096',\n",
       "   '335-361097',\n",
       "   '335-361098',\n",
       "   '335-361099',\n",
       "   '335-361101',\n",
       "   '335-361102',\n",
       "   '335-361103',\n",
       "   '335-361104',\n",
       "   '335-361287',\n",
       "   '335-361288',\n",
       "   '335-361289',\n",
       "   '335-361291',\n",
       "   '335-361292',\n",
       "   '335-361293',\n",
       "   '335-361294'],\n",
       "  'opml_class_numcat_group': ['334-361110',\n",
       "   '334-361111',\n",
       "   '334-361113',\n",
       "   '334-361282',\n",
       "   '334-361283',\n",
       "   '334-361285',\n",
       "   '334-361286']},\n",
       " 'applications': {'opml_reg_purnum_group': ['LCN_reg', 'LLN_reg'],\n",
       "  'opml_reg_numcat_group': ['LCN_reg', 'LLN_reg'],\n",
       "  'opml_class_purnum_group': ['LCN_cls', 'LLN_cls'],\n",
       "  'opml_class_numcat_group': ['LCN_cls', 'LLN_cls']},\n",
       " 'run_id': '\"error\":\"{\\\\\"message\\\\\":\\\\\"Cannot access member \\'length\\' of undefined\\\\\",\\\\\"name\\\\\":\\\\\"TypeError\\\\\"}\",\"error_code\":\"FunctionExecutionError\",\"link\":\"https://realm.mongodb.com/groups/64c03018b2c07a5e4ef40e59/apps/64c0314e1b6168a5423a9e14/logs?co_id=650b0374b1c9a3a32638a60f\"',\n",
       " 'stuck_task': '',\n",
       " 'prev_task': '',\n",
       " 'prev_X': None,\n",
       " 'prev_Y': None,\n",
       " 'prev_categorical_indicator': None,\n",
       " 'prev_attribute_names': None,\n",
       " 'orchname': 'bart',\n",
       " 'orchseceret': 'b8d206dce517c35e156cf7a5da01fc7b2fb095ae05028968ed6ba3be211df85f2dbc59b232bd53520206a1c73c65f14f9b266d9aeeadcc38e5a525c306e65628',\n",
       " 'openMLAPIKey': 'b6e6eb2fef7bd5a6af1c54893d8fc277',\n",
       " 'verbose': True,\n",
       " 'suites_ids': [336, 335, 337, 334],\n",
       " 'suites': [OpenML Benchmark Suite\n",
       "  ======================\n",
       "  ID..............: 336\n",
       "  Name............: Tabular benchmark numerical regression\n",
       "  Status..........: in_preparation\n",
       "  Main Entity Type: task\n",
       "  Study URL.......: https://www.openml.org/s/336\n",
       "  # of Data.......: 19\n",
       "  # of Tasks......: 19\n",
       "  Creator.........: https://www.openml.org/u/26324\n",
       "  Upload Time.....: 2023-01-16 03:42:12,\n",
       "  OpenML Benchmark Suite\n",
       "  ======================\n",
       "  ID..............: 335\n",
       "  Name............: Tabular benchmark categorical regression\n",
       "  Status..........: in_preparation\n",
       "  Main Entity Type: task\n",
       "  Study URL.......: https://www.openml.org/s/335\n",
       "  # of Data.......: 17\n",
       "  # of Tasks......: 17\n",
       "  Creator.........: https://www.openml.org/u/26324\n",
       "  Upload Time.....: 2023-01-16 03:40:57,\n",
       "  OpenML Benchmark Suite\n",
       "  ======================\n",
       "  ID..............: 337\n",
       "  Name............: Tabular benchmark numerical classification\n",
       "  Status..........: in_preparation\n",
       "  Main Entity Type: task\n",
       "  Study URL.......: https://www.openml.org/s/337\n",
       "  # of Data.......: 16\n",
       "  # of Tasks......: 16\n",
       "  Creator.........: https://www.openml.org/u/26324\n",
       "  Upload Time.....: 2023-01-16 03:45:23,\n",
       "  OpenML Benchmark Suite\n",
       "  ======================\n",
       "  ID..............: 334\n",
       "  Name............: Tabular benchmark categorical classification\n",
       "  Status..........: in_preparation\n",
       "  Main Entity Type: task\n",
       "  Study URL.......: https://www.openml.org/s/334\n",
       "  # of Data.......: 7\n",
       "  # of Tasks......: 7\n",
       "  Creator.........: https://www.openml.org/u/26324\n",
       "  Upload Time.....: 2023-01-16 03:22:41],\n",
       " 'taskID_suite': [(361072,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361073,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361074,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361076,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361077,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361078,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361079,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361080,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361081,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361082,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361083,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361084,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361085,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361086,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361087,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361088,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361279,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361280,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361281,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 336\n",
       "   Name............: Tabular benchmark numerical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/336\n",
       "   # of Data.......: 19\n",
       "   # of Tasks......: 19\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:42:12),\n",
       "  (361093,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361094,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361096,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361097,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361098,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361099,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361101,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361102,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361103,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361104,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361287,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361288,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361289,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361291,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361292,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361293,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361294,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 335\n",
       "   Name............: Tabular benchmark categorical regression\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/335\n",
       "   # of Data.......: 17\n",
       "   # of Tasks......: 17\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:40:57),\n",
       "  (361055,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361060,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361061,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361062,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361063,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361065,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361066,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361068,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361069,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361070,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361273,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361274,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361275,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361276,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361277,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361278,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 337\n",
       "   Name............: Tabular benchmark numerical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/337\n",
       "   # of Data.......: 16\n",
       "   # of Tasks......: 16\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:45:23),\n",
       "  (361110,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 334\n",
       "   Name............: Tabular benchmark categorical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/334\n",
       "   # of Data.......: 7\n",
       "   # of Tasks......: 7\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:22:41),\n",
       "  (361111,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 334\n",
       "   Name............: Tabular benchmark categorical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/334\n",
       "   # of Data.......: 7\n",
       "   # of Tasks......: 7\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:22:41),\n",
       "  (361113,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 334\n",
       "   Name............: Tabular benchmark categorical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/334\n",
       "   # of Data.......: 7\n",
       "   # of Tasks......: 7\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:22:41),\n",
       "  (361282,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 334\n",
       "   Name............: Tabular benchmark categorical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/334\n",
       "   # of Data.......: 7\n",
       "   # of Tasks......: 7\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:22:41),\n",
       "  (361283,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 334\n",
       "   Name............: Tabular benchmark categorical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/334\n",
       "   # of Data.......: 7\n",
       "   # of Tasks......: 7\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:22:41),\n",
       "  (361285,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 334\n",
       "   Name............: Tabular benchmark categorical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/334\n",
       "   # of Data.......: 7\n",
       "   # of Tasks......: 7\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:22:41),\n",
       "  (361286,\n",
       "   OpenML Benchmark Suite\n",
       "   ======================\n",
       "   ID..............: 334\n",
       "   Name............: Tabular benchmark categorical classification\n",
       "   Status..........: in_preparation\n",
       "   Main Entity Type: task\n",
       "   Study URL.......: https://www.openml.org/s/334\n",
       "   # of Data.......: 7\n",
       "   # of Tasks......: 7\n",
       "   Creator.........: https://www.openml.org/u/26324\n",
       "   Upload Time.....: 2023-01-16 03:22:41)],\n",
       " 'runs_per_pair': 60}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled 999 points in the space:\n",
      "{'depth': {'distribution': 'categorical', 'values': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]}, 'seed': {'distribution': 'constant', 'value': 42}, 'drop_type': {'distribution': 'constant', 'value': 'isDropConnect'}, 'p': {'distribution': 'categorical', 'values': [0, 0, 0.25, 0.5, 0.75]}, 'ensemble_n': {'distribution': 'constant', 'value': 1}, 'shrinkage': {'distribution': 'constant', 'value': 1}, 'back_n': {'distribution': 'categorical', 'values': [0, 1, 2, 3, 4]}, 'net_type': {'distribution': 'constant', 'value': 'locally_constant'}, 'hidden_dim': {'distribution': 'constant', 'value': 1}, 'anneal': {'distribution': 'constant', 'value': 'none'}, 'optimizer': {'distribution': 'categorical', 'values': ['SGD', 'SGD', 'SGD', 'SGD', 'AMSGrad']}, 'batch_size': {'distribution': 'constant', 'value': 64}, 'epochs': {'distribution': 'constant', 'value': 30}, 'lr': {'distribution': 'log_uniform', 'min': 0.05, 'max': 0.2}, 'momentum': {'distribution': 'constant', 'value': 0.9}, 'no_cuda': {'distribution': 'constant', 'value': False}, 'lr_step_size': {'distribution': 'constant', 'value': 10}, 'gamma': {'distribution': 'constant', 'value': 0.1}, 'task': {'distribution': 'constant', 'value': 'regression'}}\n",
      "========== LCN_reg ==========\n",
      "   depth  seed      drop_type    p  ensemble_n  shrinkage  back_n   \n",
      "0      5    42  isDropConnect  0.0           1          1       0  \\\n",
      "1      9    42  isDropConnect  0.5           1          1       3   \n",
      "2     10    42  isDropConnect  0.5           1          1       3   \n",
      "3      7    42  isDropConnect  0.0           1          1       4   \n",
      "4      8    42  isDropConnect  0.5           1          1       2   \n",
      "\n",
      "           net_type  hidden_dim anneal optimizer  batch_size  epochs   \n",
      "0  locally_constant           1   none       SGD          64      30  \\\n",
      "1  locally_constant           1   none       SGD          64      30   \n",
      "2  locally_constant           1   none       SGD          64      30   \n",
      "3  locally_constant           1   none       SGD          64      30   \n",
      "4  locally_constant           1   none       SGD          64      30   \n",
      "\n",
      "         lr  momentum  no_cuda  lr_step_size  gamma        task  \n",
      "0  0.182483       0.9    False            10    0.1  regression  \n",
      "1  0.059102       0.9    False            10    0.1  regression  \n",
      "2  0.130415       0.9    False            10    0.1  regression  \n",
      "3  0.087121       0.9    False            10    0.1  regression  \n",
      "4  0.083831       0.9    False            10    0.1  regression  \n",
      "sampled 999 points in the space:\n",
      "{'depth': {'distribution': 'categorical', 'values': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]}, 'seed': {'distribution': 'constant', 'value': 42}, 'drop_type': {'distribution': 'constant', 'value': 'isDropConnect'}, 'p': {'distribution': 'categorical', 'values': [0, 0, 0.25, 0.5, 0.75]}, 'ensemble_n': {'distribution': 'constant', 'value': 1}, 'shrinkage': {'distribution': 'constant', 'value': 1}, 'back_n': {'distribution': 'constant', 'value': 0}, 'net_type': {'distribution': 'constant', 'value': 'locally_constant'}, 'hidden_dim': {'distribution': 'constant', 'value': 1}, 'anneal': {'distribution': 'constant', 'value': 'none'}, 'optimizer': {'distribution': 'categorical', 'values': ['SGD', 'SGD', 'SGD', 'SGD', 'AMSGrad']}, 'batch_size': {'distribution': 'constant', 'value': 64}, 'epochs': {'distribution': 'constant', 'value': 30}, 'lr': {'distribution': 'log_uniform', 'min': 0.05, 'max': 0.2}, 'momentum': {'distribution': 'constant', 'value': 0.9}, 'no_cuda': {'distribution': 'constant', 'value': False}, 'lr_step_size': {'distribution': 'constant', 'value': 10}, 'gamma': {'distribution': 'constant', 'value': 0.1}, 'task': {'distribution': 'constant', 'value': 'classification'}}\n",
      "========== LCN_cls ==========\n",
      "   depth  seed      drop_type     p  ensemble_n  shrinkage  back_n   \n",
      "0      6    42  isDropConnect  0.50           1          1       0  \\\n",
      "1      8    42  isDropConnect  0.00           1          1       0   \n",
      "2     12    42  isDropConnect  0.75           1          1       0   \n",
      "3      2    42  isDropConnect  0.50           1          1       0   \n",
      "4      8    42  isDropConnect  0.25           1          1       0   \n",
      "\n",
      "           net_type  hidden_dim anneal optimizer  batch_size  epochs   \n",
      "0  locally_constant           1   none       SGD          64      30  \\\n",
      "1  locally_constant           1   none       SGD          64      30   \n",
      "2  locally_constant           1   none   AMSGrad          64      30   \n",
      "3  locally_constant           1   none   AMSGrad          64      30   \n",
      "4  locally_constant           1   none   AMSGrad          64      30   \n",
      "\n",
      "         lr  momentum  no_cuda  lr_step_size  gamma            task  \n",
      "0  0.074027       0.9    False            10    0.1  classification  \n",
      "1  0.123789       0.9    False            10    0.1  classification  \n",
      "2  0.052570       0.9    False            10    0.1  classification  \n",
      "3  0.115526       0.9    False            10    0.1  classification  \n",
      "4  0.081605       0.9    False            10    0.1  classification  \n",
      "sampled 999 points in the space:\n",
      "{'depth': {'distribution': 'categorical', 'values': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]}, 'seed': {'distribution': 'constant', 'value': 42}, 'drop_type': {'distribution': 'constant', 'value': 'isDropConnect'}, 'p': {'distribution': 'categorical', 'values': [0, 0, 0.25, 0.5, 0.75]}, 'ensemble_n': {'distribution': 'constant', 'value': 1}, 'shrinkage': {'distribution': 'constant', 'value': 1}, 'back_n': {'distribution': 'categorical', 'values': [0, 1, 2, 3, 4]}, 'net_type': {'distribution': 'constant', 'value': 'locally_linear'}, 'hidden_dim': {'distribution': 'constant', 'value': 1}, 'anneal': {'distribution': 'constant', 'value': 'none'}, 'optimizer': {'distribution': 'categorical', 'values': ['SGD', 'SGD', 'SGD', 'SGD', 'AMSGrad']}, 'batch_size': {'distribution': 'constant', 'value': 64}, 'epochs': {'distribution': 'constant', 'value': 30}, 'lr': {'distribution': 'log_uniform', 'min': 0.05, 'max': 0.2}, 'momentum': {'distribution': 'constant', 'value': 0.9}, 'no_cuda': {'distribution': 'constant', 'value': False}, 'lr_step_size': {'distribution': 'constant', 'value': 10}, 'gamma': {'distribution': 'constant', 'value': 0.1}, 'task': {'distribution': 'constant', 'value': 'regression'}}\n",
      "========== LLN_reg ==========\n",
      "   depth  seed      drop_type     p  ensemble_n  shrinkage  back_n   \n",
      "0      5    42  isDropConnect  0.50           1          1       0  \\\n",
      "1      9    42  isDropConnect  0.50           1          1       4   \n",
      "2      2    42  isDropConnect  0.00           1          1       4   \n",
      "3      6    42  isDropConnect  0.25           1          1       2   \n",
      "4      4    42  isDropConnect  0.25           1          1       3   \n",
      "\n",
      "         net_type  hidden_dim anneal optimizer  batch_size  epochs        lr   \n",
      "0  locally_linear           1   none   AMSGrad          64      30  0.156980  \\\n",
      "1  locally_linear           1   none       SGD          64      30  0.055116   \n",
      "2  locally_linear           1   none       SGD          64      30  0.155786   \n",
      "3  locally_linear           1   none       SGD          64      30  0.190421   \n",
      "4  locally_linear           1   none       SGD          64      30  0.058107   \n",
      "\n",
      "   momentum  no_cuda  lr_step_size  gamma        task  \n",
      "0       0.9    False            10    0.1  regression  \n",
      "1       0.9    False            10    0.1  regression  \n",
      "2       0.9    False            10    0.1  regression  \n",
      "3       0.9    False            10    0.1  regression  \n",
      "4       0.9    False            10    0.1  regression  \n",
      "sampled 999 points in the space:\n",
      "{'depth': {'distribution': 'categorical', 'values': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]}, 'seed': {'distribution': 'constant', 'value': 42}, 'drop_type': {'distribution': 'constant', 'value': 'isDropConnect'}, 'p': {'distribution': 'categorical', 'values': [0, 0, 0.25, 0.5, 0.75]}, 'ensemble_n': {'distribution': 'constant', 'value': 1}, 'shrinkage': {'distribution': 'constant', 'value': 1}, 'back_n': {'distribution': 'constant', 'value': 0}, 'net_type': {'distribution': 'constant', 'value': 'locally_linear'}, 'hidden_dim': {'distribution': 'constant', 'value': 1}, 'anneal': {'distribution': 'constant', 'value': 'none'}, 'optimizer': {'distribution': 'categorical', 'values': ['SGD', 'SGD', 'SGD', 'SGD', 'AMSGrad']}, 'batch_size': {'distribution': 'constant', 'value': 64}, 'epochs': {'distribution': 'constant', 'value': 30}, 'lr': {'distribution': 'log_uniform', 'min': 0.05, 'max': 0.2}, 'momentum': {'distribution': 'constant', 'value': 0.9}, 'no_cuda': {'distribution': 'constant', 'value': False}, 'lr_step_size': {'distribution': 'constant', 'value': 10}, 'gamma': {'distribution': 'constant', 'value': 0.1}, 'task': {'distribution': 'constant', 'value': 'classification'}}\n",
      "========== LLN_cls ==========\n",
      "   depth  seed      drop_type     p  ensemble_n  shrinkage  back_n   \n",
      "0      9    42  isDropConnect  0.00           1          1       0  \\\n",
      "1      4    42  isDropConnect  0.75           1          1       0   \n",
      "2     11    42  isDropConnect  0.50           1          1       0   \n",
      "3     12    42  isDropConnect  0.75           1          1       0   \n",
      "4      8    42  isDropConnect  0.00           1          1       0   \n",
      "\n",
      "         net_type  hidden_dim anneal optimizer  batch_size  epochs        lr   \n",
      "0  locally_linear           1   none       SGD          64      30  0.062215  \\\n",
      "1  locally_linear           1   none       SGD          64      30  0.050261   \n",
      "2  locally_linear           1   none       SGD          64      30  0.112959   \n",
      "3  locally_linear           1   none   AMSGrad          64      30  0.109086   \n",
      "4  locally_linear           1   none       SGD          64      30  0.076908   \n",
      "\n",
      "   momentum  no_cuda  lr_step_size  gamma            task  \n",
      "0       0.9    False            10    0.1  classification  \n",
      "1       0.9    False            10    0.1  classification  \n",
      "2       0.9    False            10    0.1  classification  \n",
      "3       0.9    False            10    0.1  classification  \n",
      "4       0.9    False            10    0.1  classification  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "spaces = {\n",
    "    'LCN_reg':LCN_reg_space,\n",
    "    'LCN_cls':LCN_cls_space,\n",
    "    'LLN_reg':LLN_reg_space,\n",
    "    'LLN_cls':LLN_cls_space\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"Defining general visualization funciton\n",
    "plot all hyperparameter distributions for all hyperparameters\n",
    "\"\"\"\n",
    "def vis(df, title, print_only=True):\n",
    "\n",
    "    print('========== {} =========='.format(title))\n",
    "    print(df.head())\n",
    "\n",
    "    if print_only:\n",
    "        return\n",
    "\n",
    "    fig, axs = plt.subplots(len(df.columns)-1, 1)\n",
    "    for col, ax in zip(df.columns[1:], axs):\n",
    "        ax.hist(df[col], bins=50)\n",
    "        ax.set_ylabel(col)\n",
    "\n",
    "    fig.set_size_inches(18.5, 20)\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "#monte carlo sampled hyperparameters for each range\n",
    "space_samples = {}\n",
    "\n",
    "#visualizing all spaces\n",
    "if True:\n",
    "    for k, v in spaces.items():\n",
    "        output = ex.monte_carlo_sample_space(v)\n",
    "        space_samples[k] = pd.DataFrame(output)\n",
    "        vis(space_samples[k], k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics(model, test_loader, hyperparameters, test_set_name=None):\n",
    "        if test_set_name:\n",
    "            assert isinstance(test_set_name, str), \"test_set_name must be a string, such as train, val, test\"\n",
    "            \n",
    "        no_cuda = hyperparameters['no_cuda']    \n",
    "        use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            dataset_len = 0\n",
    "            standard_errors_list = []\n",
    "            target_list = []\n",
    "\n",
    "            for data, target in test_loader:\n",
    "                dataset_len += len(target)\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                target_list.append(target)\n",
    "\n",
    "                ###############\n",
    "                data.requires_grad = True\n",
    "                if model.net_type == 'locally_constant':\n",
    "                    output, relu_masks = model(data, p=0, training=False)\n",
    "                elif model.net_type == 'locally_linear':\n",
    "                    output, relu_masks = model.normal_forward(data, p=0, training=False)\n",
    "                ###############\n",
    "\n",
    "                standard_errors = ((output - target) ** 2)\n",
    "                # print(standard_errors.shape)\n",
    "                # print(target.shape)\n",
    "                standard_errors_list.append(standard_errors)\n",
    "                test_loss += ((output - target) ** 2).mean().item() * len(target)\n",
    "\n",
    "            test_loss /= dataset_len\n",
    "            \n",
    "            standard_errors_tensor = torch.cat(standard_errors_list, dim=0)\n",
    "            all_targets = torch.cat(target_list, dim=0)\n",
    "\n",
    "            \n",
    "            standard_errors_tensor = torch.squeeze(standard_errors_tensor)\n",
    "            all_targets = torch.squeeze(all_targets)\n",
    "            \n",
    "            print(standard_errors_tensor.shape)\n",
    "            print(all_targets.shape)\n",
    "\n",
    "\n",
    "            ss_res = torch.sum(standard_errors_tensor)\n",
    "            target_mean = torch.mean(all_targets)\n",
    "            ss_tot = torch.sum((all_targets - target_mean) ** 2)\n",
    "            r2_score = 1 - (ss_res / ss_tot)\n",
    "            \n",
    "            # print(ss_res)\n",
    "            # print(target_mean)\n",
    "            # print(ss_tot)\n",
    "            # print(r2_score)\n",
    "\n",
    "            RMSE = float(np.sqrt(test_loss))\n",
    "\n",
    "            quantiles = torch.tensor(self.quantiles, device=device)\n",
    "            quantile_values = torch.quantile(standard_errors_tensor, quantiles)\n",
    "\n",
    "            # standard_errors_pd = pd.DataFrame(standard_errors_tensor.cpu().numpy())\n",
    "            # quantile_dict = standard_errors_pd.quantile(self.quantiles).to_dict()\n",
    "\n",
    "            quantile_dict = {q: float(v.item()) for q, v in zip(self.quantiles, quantile_values)}\n",
    "\n",
    "            metrics = {\n",
    "                'RMSE': RMSE,\n",
    "                'r2_score': r2_score.cpu().item(),\n",
    "                'se_quant': quantile_dict}\n",
    "\n",
    "            if test_set_name:\n",
    "                assert isinstance(test_set_name, str), \"test_set_name must be a string, such as 'train', 'val', 'test'\"\n",
    "                metrics_name = f'{test_set_name}_metrics'\n",
    "                final_metrics = {metrics_name: metrics}\n",
    "            else:\n",
    "                final_metrics = {'metrics': metrics}\n",
    "\n",
    "\n",
    "            return final_metrics\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "authorship_tag": "ABX9TyO6d7scFvmxtcd+gePzcxnN",
   "provenance": []
  },
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-2:712779665605:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
